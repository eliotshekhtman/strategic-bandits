{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d54b5828",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVC\n",
    "import cvxpy as cp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2656ffcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.79109255e-19  2.85112420e-02  2.79973443e-19  3.37658729e-20\n",
      " -2.72802663e-19  1.49285011e-01 -9.94082533e-20  8.35373900e-20\n",
      "  2.46718649e-01  5.78224144e-01 -4.03739463e-19  1.01242860e-03\n",
      " -9.28486180e-20  2.26767464e-01 -1.58813678e-19 -8.97232272e-20\n",
      " -1.22145729e-19 -1.51509428e-19  1.12060672e-19 -3.48318635e-19]\n",
      "[ 2.50938945  0.          2.78354615  1.79425782 13.08579183  0.\n",
      "  0.73716363  3.35344995  0.          0.          8.93825054  0.\n",
      "  7.02955161  0.          4.71068649  3.18873635  2.06090107 10.08166738\n",
      "  3.0481157   8.53268239]\n"
     ]
    }
   ],
   "source": [
    "# Problem data.\n",
    "m = 30\n",
    "n = 20\n",
    "np.random.seed(1)\n",
    "A = np.random.randn(m, n)\n",
    "b = np.random.randn(m)\n",
    "\n",
    "# Construct the problem.\n",
    "x = cp.Variable(n)\n",
    "objective = cp.Minimize(cp.sum_squares(A @ x - b))\n",
    "constraints = [0 <= x, x <= 1]\n",
    "prob = cp.Problem(objective, constraints)\n",
    "\n",
    "# The optimal objective value is returned by `prob.solve()`.\n",
    "result = prob.solve()\n",
    "# The optimal value for x is stored in `x.value`.\n",
    "print(x.value)\n",
    "# The optimal Lagrange multiplier for a constraint is stored in\n",
    "# `constraint.dual_value`.\n",
    "print(constraints[0].dual_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a18c4c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(M, axis=-1):\n",
    "    return cp.exp(M - cp.log(cp.sum(cp.exp(M), axis=axis, keepdims=True)))\n",
    "\n",
    "def l1norm_agent(X, phi, b, u):\n",
    "    \"\"\"\n",
    "    Params\n",
    "    ------\n",
    "    X : (d,)\n",
    "    phi : (m,d)\n",
    "    b : (m,)\n",
    "    u : (m,)\n",
    "    \"\"\"\n",
    "    d, = X.shape\n",
    "    m, = b.shape\n",
    "    one_m = np.ones(m)\n",
    "    X_hat = cp.Variable(d)\n",
    "    \n",
    "    objective = cp.Maximize(u @ (phi @ X_hat + b) / (one_m @ (phi @ X_hat + b)) - 0.5 * cp.sum_squares(X - X_hat))\n",
    "    constraints = [-X_hat <= 0]\n",
    "    prob = cp.Problem(objective, constraints)#, constraints)\n",
    "    result = prob.solve()#qcp=True)\n",
    "    \n",
    "    return X_hat.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5fc9b42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lfp(A, b, c, d, alpha, beta):\n",
    "    m, n = A.shape\n",
    "    \n",
    "    x = cp.Variable(n)\n",
    "    objective = cp.Maximize((c @ x + alpha) / (d @ x + beta))\n",
    "    constraints = [x >= 0]\n",
    "    prob = cp.Problem(objective, constraints)\n",
    "    result = prob.solve(qcp=True)\n",
    "    \n",
    "    return x.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1257049a",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 3\n",
    "n = 2\n",
    "A = np.random.rand(m, n)\n",
    "b = np.random.rand(m)\n",
    "c = np.random.rand(n)\n",
    "d = np.random.rand(n)\n",
    "alpha = np.random.rand()\n",
    "beta = np.random.rand()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "50db7791",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.68245371, 0.22820573],\n",
       "        [0.01376751, 0.41672396],\n",
       "        [0.93848189, 0.34302811]]),\n",
       " array([0.7797443 , 0.17473631, 0.34195284]),\n",
       " array([0.14459772, 0.71677081]),\n",
       " array([0.69930762, 0.68849732]),\n",
       " 0.25339603448629966,\n",
       " 0.6923601216234089)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A, b, c, d, alpha, beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ee3d2f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lfp(A, b, c, d, alpha, beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "32d7080b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(0.50000165)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = cp.Variable()\n",
    "concave_fractional_fn = cp.sqrt(x) / cp.exp(x)\n",
    "problem = cp.Problem(cp.Maximize(concave_fractional_fn))\n",
    "assert problem.is_dqcp()\n",
    "problem.solve(qcp=True)\n",
    "x.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 776,
   "id": "8713beaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = 2\n",
    "m = 2\n",
    "X = np.ones(d)\n",
    "phi = np.ones((m, d))\n",
    "b = np.ones(m)\n",
    "u = np.ones(m)\n",
    "one_m = np.ones(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 777,
   "id": "b9abc19e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 777,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u @ (phi @ X) / (one_m @ (phi @ X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 778,
   "id": "3acd0f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# l1norm_agent(X, phi, b, u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 779,
   "id": "4c420fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 780,
   "id": "9a83587f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def criterion(X_hat, X, phi, b, u):\n",
    "    m, = b.shape\n",
    "    one_m = torch.ones(m)\n",
    "    action = phi @ X_hat + b\n",
    "    reward = u @ action / (one_m @ action)\n",
    "    cost = torch.sum((X - X_hat) ** 2)\n",
    "    return - (reward - 0.5 * cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 781,
   "id": "e1c06505",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_hat = torch.tensor([1.] * d)\n",
    "X = torch.tensor([2.] * d)\n",
    "phi = torch.tensor(phi, dtype=torch.float32)\n",
    "b = torch.tensor(b, dtype=torch.float32)\n",
    "u = torch.tensor(u, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 782,
   "id": "f0442ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_hat.requires_grad_(True)\n",
    "optimizer = torch.optim.SGD([X_hat], lr=0.01, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 783,
   "id": "54602b81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1.0100, 1.0100], requires_grad=True),\n",
       " tensor(-0., grad_fn=<NegBackward0>))"
      ]
     },
     "execution_count": 783,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer.zero_grad()\n",
    "loss = criterion(X_hat, X, phi, b, u)\n",
    "loss.backward()\n",
    "optimizer.step()\n",
    "X_hat, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 903,
   "id": "5637f75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def l1norm_gragent(X, phi, b, u):\n",
    "    m, d = phi.shape\n",
    "    one_m = torch.ones(m)\n",
    "    X_hat = torch.rand(d)\n",
    "    X_hat.requires_grad_(True)\n",
    "    optimizer = torch.optim.SGD([X_hat], lr=0.01, momentum=0.9)\n",
    "    for _ in range(300):\n",
    "        optimizer.zero_grad()\n",
    "        action = phi @ X_hat + b\n",
    "        reward = u @ action / (one_m @ action)\n",
    "        cost = torch.sum((X - X_hat) ** 2)\n",
    "        loss = - (reward - 0.5 * cost)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # print(loss)\n",
    "    return X_hat\n",
    "\n",
    "def softmax_gragent(X, phi, b, u):\n",
    "    m, d = phi.shape\n",
    "    one_m = torch.ones(m)\n",
    "    X_hat = torch.rand(d)\n",
    "    X_hat.requires_grad_(True)\n",
    "    softmax = nn.Softmax()\n",
    "    optimizer = torch.optim.SGD([X_hat], lr=0.01, momentum=0.9)\n",
    "    for _ in range(300):\n",
    "        optimizer.zero_grad()\n",
    "        reward = u @ softmax(phi @ X_hat + b)\n",
    "        cost = torch.sum((X - X_hat) ** 2)\n",
    "        loss = - (reward - 0.5 * cost)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # print(loss)\n",
    "    return X_hat\n",
    "\n",
    "def l1norm_decision_maker_criterion(Xs_hat, Xs, phi, b, W, u):\n",
    "    Xs_hat = Xs_hat.T\n",
    "    Xs = Xs.T\n",
    "    d, m = W.shape\n",
    "    one_m = torch.ones(m)\n",
    "    action = phi @ Xs_hat + b.reshape(-1, 1) # md @ dn + m --> mn\n",
    "    penalty = 0\n",
    "    reward = X @ (W @ action / (one_m @ action)) # nd @ (dm @ mn / (m @ mn)) --> n\n",
    "    for i in range(d):\n",
    "        pen_i = Xs[i] * Xs_hat[i] # n\n",
    "        for j in range(d):\n",
    "            pen_i -= ((u @ phi[:, i]) * (one_m @ phi[:, j]) + (u @ phi[:, j]) * (one_m @ phi[:, i])) * Xs_hat[i] * Xs_hat[j]\n",
    "        pen_i += 2 * Xs_hat[i] ** 2\n",
    "        penalty -= pen_i ** 2\n",
    "    # print(reward, penalty)\n",
    "    return torch.sum(reward)\n",
    "    \n",
    "\n",
    "def l1norm_phi(Xs, W, u):\n",
    "    d, m = W.shape\n",
    "    # one_m = torch.ones(m)\n",
    "    Xs_hat = Xs.clone()\n",
    "    Xs_hat.requires_grad_(True)\n",
    "    phi = torch.rand((m, d))\n",
    "    phi.requires_grad_(True)\n",
    "    b = torch.zeros(m)\n",
    "    b.requires_grad_(True)\n",
    "    optimizer = torch.optim.Adam([Xs_hat, phi, b], lr=0.0001)\n",
    "    for _ in range(300):\n",
    "        optimizer.zero_grad()\n",
    "        loss = -l1norm_decision_maker_criterion(Xs_hat, Xs, phi, b, W, u)\n",
    "        # print(loss)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    return phi, b\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 905,
   "id": "c90ea51a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.4115, 0.4050, 0.4071, 0.4052, 0.4169], grad_fn=<SqueezeBackward3>) tensor([-0.9453, -5.6546, -7.0174, -3.9155, -1.3345], grad_fn=<SubBackward0>)\n",
      "tensor(-2.0457, grad_fn=<NegBackward0>)\n",
      "tensor([0.4116, 0.4051, 0.4072, 0.4053, 0.4170], grad_fn=<SqueezeBackward3>) tensor([-0.9458, -5.6538, -7.0176, -3.9150, -1.3351], grad_fn=<SubBackward0>)\n",
      "tensor(-2.0461, grad_fn=<NegBackward0>)\n",
      "tensor([0.4117, 0.4051, 0.4072, 0.4054, 0.4171], grad_fn=<SqueezeBackward3>) tensor([-0.9462, -5.6529, -7.0179, -3.9145, -1.3357], grad_fn=<SubBackward0>)\n",
      "tensor(-2.0464, grad_fn=<NegBackward0>)\n",
      "tensor([0.4117, 0.4052, 0.4073, 0.4054, 0.4172], grad_fn=<SqueezeBackward3>) tensor([-0.9466, -5.6521, -7.0181, -3.9140, -1.3363], grad_fn=<SubBackward0>)\n",
      "tensor(-2.0468, grad_fn=<NegBackward0>)\n",
      "tensor([0.4118, 0.4052, 0.4073, 0.4055, 0.4173], grad_fn=<SqueezeBackward3>) tensor([-0.9470, -5.6513, -7.0183, -3.9135, -1.3369], grad_fn=<SubBackward0>)\n",
      "tensor(-2.0472, grad_fn=<NegBackward0>)\n",
      "tensor([0.4119, 0.4053, 0.4074, 0.4055, 0.4173], grad_fn=<SqueezeBackward3>) tensor([-0.9475, -5.6505, -7.0186, -3.9130, -1.3375], grad_fn=<SubBackward0>)\n",
      "tensor(-2.0475, grad_fn=<NegBackward0>)\n",
      "tensor([0.4120, 0.4054, 0.4075, 0.4056, 0.4174], grad_fn=<SqueezeBackward3>) tensor([-0.9479, -5.6497, -7.0188, -3.9125, -1.3382], grad_fn=<SubBackward0>)\n",
      "tensor(-2.0479, grad_fn=<NegBackward0>)\n",
      "tensor([0.4121, 0.4054, 0.4075, 0.4057, 0.4175], grad_fn=<SqueezeBackward3>) tensor([-0.9483, -5.6488, -7.0191, -3.9120, -1.3388], grad_fn=<SubBackward0>)\n",
      "tensor(-2.0482, grad_fn=<NegBackward0>)\n",
      "tensor([0.4121, 0.4055, 0.4076, 0.4057, 0.4176], grad_fn=<SqueezeBackward3>) tensor([-0.9487, -5.6480, -7.0193, -3.9115, -1.3394], grad_fn=<SubBackward0>)\n",
      "tensor(-2.0486, grad_fn=<NegBackward0>)\n",
      "tensor([0.4122, 0.4056, 0.4076, 0.4058, 0.4177], grad_fn=<SqueezeBackward3>) tensor([-0.9491, -5.6472, -7.0196, -3.9110, -1.3399], grad_fn=<SubBackward0>)\n",
      "tensor(-2.0489, grad_fn=<NegBackward0>)\n",
      "tensor([0.4123, 0.4056, 0.4077, 0.4059, 0.4178], grad_fn=<SqueezeBackward3>) tensor([-0.9496, -5.6464, -7.0198, -3.9105, -1.3405], grad_fn=<SubBackward0>)\n",
      "tensor(-2.0493, grad_fn=<NegBackward0>)\n",
      "tensor([0.4124, 0.4057, 0.4078, 0.4059, 0.4179], grad_fn=<SqueezeBackward3>) tensor([-0.9500, -5.6456, -7.0200, -3.9100, -1.3411], grad_fn=<SubBackward0>)\n",
      "tensor(-2.0496, grad_fn=<NegBackward0>)\n",
      "tensor([0.4125, 0.4057, 0.4078, 0.4060, 0.4179], grad_fn=<SqueezeBackward3>) tensor([-0.9504, -5.6447, -7.0203, -3.9095, -1.3417], grad_fn=<SubBackward0>)\n",
      "tensor(-2.0500, grad_fn=<NegBackward0>)\n",
      "tensor([0.4125, 0.4058, 0.4079, 0.4061, 0.4180], grad_fn=<SqueezeBackward3>) tensor([-0.9508, -5.6439, -7.0205, -3.9090, -1.3423], grad_fn=<SubBackward0>)\n",
      "tensor(-2.0503, grad_fn=<NegBackward0>)\n",
      "tensor([0.4126, 0.4059, 0.4079, 0.4061, 0.4181], grad_fn=<SqueezeBackward3>) tensor([-0.9512, -5.6431, -7.0208, -3.9086, -1.3429], grad_fn=<SubBackward0>)\n",
      "tensor(-2.0507, grad_fn=<NegBackward0>)\n",
      "tensor([0.4127, 0.4059, 0.4080, 0.4062, 0.4182], grad_fn=<SqueezeBackward3>) tensor([-0.9517, -5.6423, -7.0210, -3.9081, -1.3434], grad_fn=<SubBackward0>)\n",
      "tensor(-2.0510, grad_fn=<NegBackward0>)\n",
      "tensor([0.4128, 0.4060, 0.4081, 0.4063, 0.4183], grad_fn=<SqueezeBackward3>) tensor([-0.9521, -5.6415, -7.0212, -3.9076, -1.3440], grad_fn=<SubBackward0>)\n",
      "tensor(-2.0514, grad_fn=<NegBackward0>)\n",
      "tensor([0.4129, 0.4061, 0.4081, 0.4063, 0.4184], grad_fn=<SqueezeBackward3>) tensor([-0.9525, -5.6407, -7.0215, -3.9071, -1.3445], grad_fn=<SubBackward0>)\n",
      "tensor(-2.0517, grad_fn=<NegBackward0>)\n",
      "tensor([0.4129, 0.4061, 0.4082, 0.4064, 0.4184], grad_fn=<SqueezeBackward3>) tensor([-0.9529, -5.6398, -7.0217, -3.9066, -1.3451], grad_fn=<SubBackward0>)\n",
      "tensor(-2.0521, grad_fn=<NegBackward0>)\n",
      "tensor([0.4130, 0.4062, 0.4082, 0.4064, 0.4185], grad_fn=<SqueezeBackward3>) tensor([-0.9533, -5.6390, -7.0220, -3.9061, -1.3456], grad_fn=<SubBackward0>)\n",
      "tensor(-2.0524, grad_fn=<NegBackward0>)\n",
      "tensor([0.4131, 0.4062, 0.4083, 0.4065, 0.4186], grad_fn=<SqueezeBackward3>) tensor([-0.9537, -5.6382, -7.0222, -3.9056, -1.3461], grad_fn=<SubBackward0>)\n",
      "tensor(-2.0528, grad_fn=<NegBackward0>)\n",
      "tensor([0.4132, 0.4063, 0.4084, 0.4066, 0.4187], grad_fn=<SqueezeBackward3>) tensor([-0.9542, -5.6374, -7.0224, -3.9051, -1.3466], grad_fn=<SubBackward0>)\n",
      "tensor(-2.0531, grad_fn=<NegBackward0>)\n",
      "tensor([0.4133, 0.4064, 0.4084, 0.4066, 0.4188], grad_fn=<SqueezeBackward3>) tensor([-0.9546, -5.6366, -7.0227, -3.9046, -1.3471], grad_fn=<SubBackward0>)\n",
      "tensor(-2.0535, grad_fn=<NegBackward0>)\n",
      "tensor([0.4133, 0.4064, 0.4085, 0.4067, 0.4189], grad_fn=<SqueezeBackward3>) tensor([-0.9550, -5.6358, -7.0229, -3.9041, -1.3476], grad_fn=<SubBackward0>)\n",
      "tensor(-2.0538, grad_fn=<NegBackward0>)\n",
      "tensor([0.4134, 0.4065, 0.4085, 0.4068, 0.4190], grad_fn=<SqueezeBackward3>) tensor([-0.9554, -5.6349, -7.0231, -3.9036, -1.3481], grad_fn=<SubBackward0>)\n",
      "tensor(-2.0542, grad_fn=<NegBackward0>)\n",
      "tensor([0.4135, 0.4066, 0.4086, 0.4068, 0.4190], grad_fn=<SqueezeBackward3>) tensor([-0.9558, -5.6341, -7.0234, -3.9031, -1.3486], grad_fn=<SubBackward0>)\n",
      "tensor(-2.0545, grad_fn=<NegBackward0>)\n",
      "tensor([0.4136, 0.4066, 0.4087, 0.4069, 0.4191], grad_fn=<SqueezeBackward3>) tensor([-0.9562, -5.6333, -7.0236, -3.9026, -1.3490], grad_fn=<SubBackward0>)\n",
      "tensor(-2.0549, grad_fn=<NegBackward0>)\n",
      "tensor([0.4137, 0.4067, 0.4087, 0.4070, 0.4192], grad_fn=<SqueezeBackward3>) tensor([-0.9566, -5.6325, -7.0238, -3.9021, -1.3495], grad_fn=<SubBackward0>)\n",
      "tensor(-2.0552, grad_fn=<NegBackward0>)\n",
      "tensor([0.4137, 0.4067, 0.4088, 0.4070, 0.4193], grad_fn=<SqueezeBackward3>) tensor([-0.9570, -5.6317, -7.0241, -3.9016, -1.3499], grad_fn=<SubBackward0>)\n",
      "tensor(-2.0556, grad_fn=<NegBackward0>)\n",
      "tensor([0.4138, 0.4068, 0.4088, 0.4071, 0.4194], grad_fn=<SqueezeBackward3>) tensor([-0.9574, -5.6308, -7.0243, -3.9011, -1.3503], grad_fn=<SubBackward0>)\n",
      "tensor(-2.0559, grad_fn=<NegBackward0>)\n",
      "tensor([0.4139, 0.4069, 0.4089, 0.4072, 0.4195], grad_fn=<SqueezeBackward3>) tensor([-0.9578, -5.6300, -7.0245, -3.9006, -1.3507], grad_fn=<SubBackward0>)\n",
      "tensor(-2.0563, grad_fn=<NegBackward0>)\n",
      "tensor([0.4140, 0.4069, 0.4090, 0.4072, 0.4195], grad_fn=<SqueezeBackward3>) tensor([-0.9582, -5.6292, -7.0247, -3.9001, -1.3510], grad_fn=<SubBackward0>)\n",
      "tensor(-2.0566, grad_fn=<NegBackward0>)\n",
      "tensor([0.4141, 0.4070, 0.4090, 0.4073, 0.4196], grad_fn=<SqueezeBackward3>) tensor([-0.9586, -5.6284, -7.0250, -3.8996, -1.3514], grad_fn=<SubBackward0>)\n",
      "tensor(-2.0570, grad_fn=<NegBackward0>)\n",
      "tensor([0.4141, 0.4071, 0.4091, 0.4074, 0.4197], grad_fn=<SqueezeBackward3>) tensor([-0.9590, -5.6276, -7.0252, -3.8991, -1.3517], grad_fn=<SubBackward0>)\n",
      "tensor(-2.0573, grad_fn=<NegBackward0>)\n",
      "tensor([0.4142, 0.4071, 0.4091, 0.4074, 0.4198], grad_fn=<SqueezeBackward3>) tensor([-0.9594, -5.6267, -7.0254, -3.8986, -1.3520], grad_fn=<SubBackward0>)\n",
      "tensor(-2.0577, grad_fn=<NegBackward0>)\n",
      "tensor([0.4143, 0.4072, 0.4092, 0.4075, 0.4199], grad_fn=<SqueezeBackward3>) tensor([-0.9598, -5.6259, -7.0256, -3.8981, -1.3523], grad_fn=<SubBackward0>)\n",
      "tensor(-2.0580, grad_fn=<NegBackward0>)\n",
      "tensor([0.4144, 0.4072, 0.4093, 0.4075, 0.4200], grad_fn=<SqueezeBackward3>) tensor([-0.9602, -5.6251, -7.0259, -3.8976, -1.3526], grad_fn=<SubBackward0>)\n",
      "tensor(-2.0584, grad_fn=<NegBackward0>)\n",
      "tensor([0.4145, 0.4073, 0.4093, 0.4076, 0.4200], grad_fn=<SqueezeBackward3>) tensor([-0.9606, -5.6243, -7.0261, -3.8971, -1.3528], grad_fn=<SubBackward0>)\n",
      "tensor(-2.0587, grad_fn=<NegBackward0>)\n",
      "tensor([0.4145, 0.4074, 0.4094, 0.4077, 0.4201], grad_fn=<SqueezeBackward3>) tensor([-0.9610, -5.6234, -7.0263, -3.8966, -1.3530], grad_fn=<SubBackward0>)\n",
      "tensor(-2.0591, grad_fn=<NegBackward0>)\n",
      "tensor([0.4146, 0.4074, 0.4094, 0.4077, 0.4202], grad_fn=<SqueezeBackward3>) tensor([-0.9614, -5.6226, -7.0265, -3.8961, -1.3532], grad_fn=<SubBackward0>)\n",
      "tensor(-2.0594, grad_fn=<NegBackward0>)\n",
      "tensor([0.4147, 0.4075, 0.4095, 0.4078, 0.4203], grad_fn=<SqueezeBackward3>) tensor([-0.9618, -5.6218, -7.0267, -3.8956, -1.3533], grad_fn=<SubBackward0>)\n",
      "tensor(-2.0598, grad_fn=<NegBackward0>)\n",
      "tensor([0.4148, 0.4075, 0.4096, 0.4079, 0.4204], grad_fn=<SqueezeBackward3>) tensor([-0.9622, -5.6210, -7.0270, -3.8951, -1.3535], grad_fn=<SubBackward0>)\n",
      "tensor(-2.0601, grad_fn=<NegBackward0>)\n",
      "tensor([0.4149, 0.4076, 0.4096, 0.4079, 0.4205], grad_fn=<SqueezeBackward3>) tensor([-0.9625, -5.6201, -7.0272, -3.8946, -1.3536], grad_fn=<SubBackward0>)\n",
      "tensor(-2.0605, grad_fn=<NegBackward0>)\n",
      "tensor([0.4149, 0.4077, 0.4097, 0.4080, 0.4206], grad_fn=<SqueezeBackward3>) tensor([-0.9629, -5.6193, -7.0274, -3.8941, -1.3536], grad_fn=<SubBackward0>)\n",
      "tensor(-2.0608, grad_fn=<NegBackward0>)\n",
      "tensor([0.4150, 0.4077, 0.4097, 0.4081, 0.4206], grad_fn=<SqueezeBackward3>) tensor([-0.9633, -5.6185, -7.0276, -3.8936, -1.3537], grad_fn=<SubBackward0>)\n",
      "tensor(-2.0612, grad_fn=<NegBackward0>)\n",
      "tensor([0.4151, 0.4078, 0.4098, 0.4081, 0.4207], grad_fn=<SqueezeBackward3>) tensor([-0.9637, -5.6176, -7.0278, -3.8931, -1.3537], grad_fn=<SubBackward0>)\n",
      "tensor(-2.0615, grad_fn=<NegBackward0>)\n",
      "tensor([0.4152, 0.4079, 0.4099, 0.4082, 0.4208], grad_fn=<SqueezeBackward3>) tensor([-0.9641, -5.6168, -7.0280, -3.8926, -1.3536], grad_fn=<SubBackward0>)\n",
      "tensor(-2.0619, grad_fn=<NegBackward0>)\n",
      "tensor([0.4153, 0.4079, 0.4099, 0.4083, 0.4209], grad_fn=<SqueezeBackward3>) tensor([-0.9644, -5.6160, -7.0282, -3.8921, -1.3536], grad_fn=<SubBackward0>)\n",
      "tensor(-2.0622, grad_fn=<NegBackward0>)\n",
      "tensor([0.4153, 0.4080, 0.4100, 0.4083, 0.4210], grad_fn=<SqueezeBackward3>) tensor([-0.9648, -5.6151, -7.0284, -3.8916, -1.3535], grad_fn=<SubBackward0>)\n",
      "tensor(-2.0626, grad_fn=<NegBackward0>)\n",
      "tensor([0.4154, 0.4080, 0.4101, 0.4084, 0.4211], grad_fn=<SqueezeBackward3>) tensor([-0.9652, -5.6143, -7.0286, -3.8911, -1.3534], grad_fn=<SubBackward0>)\n",
      "tensor(-2.0630, grad_fn=<NegBackward0>)\n",
      "tensor([0.4155, 0.4081, 0.4101, 0.4084, 0.4211], grad_fn=<SqueezeBackward3>) tensor([-0.9655, -5.6135, -7.0288, -3.8906, -1.3532], grad_fn=<SubBackward0>)\n",
      "tensor(-2.0633, grad_fn=<NegBackward0>)\n",
      "tensor([0.4156, 0.4082, 0.4102, 0.4085, 0.4212], grad_fn=<SqueezeBackward3>) tensor([-0.9659, -5.6127, -7.0290, -3.8901, -1.3530], grad_fn=<SubBackward0>)\n",
      "tensor(-2.0637, grad_fn=<NegBackward0>)\n",
      "tensor([0.4157, 0.4082, 0.4102, 0.4086, 0.4213], grad_fn=<SqueezeBackward3>) tensor([-0.9663, -5.6118, -7.0292, -3.8896, -1.3528], grad_fn=<SubBackward0>)\n",
      "tensor(-2.0640, grad_fn=<NegBackward0>)\n",
      "tensor([0.4157, 0.4083, 0.4103, 0.4086, 0.4214], grad_fn=<SqueezeBackward3>) tensor([-0.9666, -5.6110, -7.0294, -3.8891, -1.3525], grad_fn=<SubBackward0>)\n",
      "tensor(-2.0644, grad_fn=<NegBackward0>)\n",
      "tensor([0.4158, 0.4084, 0.4104, 0.4087, 0.4215], grad_fn=<SqueezeBackward3>) tensor([-0.9670, -5.6101, -7.0296, -3.8885, -1.3522], grad_fn=<SubBackward0>)\n",
      "tensor(-2.0647, grad_fn=<NegBackward0>)\n",
      "tensor([0.4159, 0.4084, 0.4104, 0.4088, 0.4216], grad_fn=<SqueezeBackward3>) tensor([-0.9674, -5.6093, -7.0298, -3.8880, -1.3519], grad_fn=<SubBackward0>)\n",
      "tensor(-2.0651, grad_fn=<NegBackward0>)\n",
      "tensor([0.4160, 0.4085, 0.4105, 0.4088, 0.4217], grad_fn=<SqueezeBackward3>) tensor([-0.9677, -5.6085, -7.0300, -3.8875, -1.3515], grad_fn=<SubBackward0>)\n",
      "tensor(-2.0654, grad_fn=<NegBackward0>)\n",
      "tensor([0.4161, 0.4085, 0.4105, 0.4089, 0.4217], grad_fn=<SqueezeBackward3>) tensor([-0.9681, -5.6076, -7.0302, -3.8870, -1.3511], grad_fn=<SubBackward0>)\n",
      "tensor(-2.0658, grad_fn=<NegBackward0>)\n",
      "tensor([0.4161, 0.4086, 0.4106, 0.4090, 0.4218], grad_fn=<SqueezeBackward3>) tensor([-0.9684, -5.6068, -7.0304, -3.8865, -1.3506], grad_fn=<SubBackward0>)\n",
      "tensor(-2.0661, grad_fn=<NegBackward0>)\n",
      "tensor([0.4162, 0.4087, 0.4107, 0.4090, 0.4219], grad_fn=<SqueezeBackward3>) tensor([-0.9688, -5.6060, -7.0306, -3.8860, -1.3502], grad_fn=<SubBackward0>)\n",
      "tensor(-2.0665, grad_fn=<NegBackward0>)\n",
      "tensor([0.4163, 0.4087, 0.4107, 0.4091, 0.4220], grad_fn=<SqueezeBackward3>) tensor([-0.9691, -5.6051, -7.0307, -3.8855, -1.3497], grad_fn=<SubBackward0>)\n",
      "tensor(-2.0668, grad_fn=<NegBackward0>)\n",
      "tensor([0.4164, 0.4088, 0.4108, 0.4091, 0.4221], grad_fn=<SqueezeBackward3>) tensor([-0.9695, -5.6043, -7.0309, -3.8849, -1.3491], grad_fn=<SubBackward0>)\n",
      "tensor(-2.0672, grad_fn=<NegBackward0>)\n",
      "tensor([0.4165, 0.4089, 0.4108, 0.4092, 0.4222], grad_fn=<SqueezeBackward3>) tensor([-0.9698, -5.6034, -7.0311, -3.8844, -1.3485], grad_fn=<SubBackward0>)\n",
      "tensor(-2.0675, grad_fn=<NegBackward0>)\n",
      "tensor([0.4165, 0.4089, 0.4109, 0.4093, 0.4222], grad_fn=<SqueezeBackward3>) tensor([-0.9701, -5.6026, -7.0313, -3.8839, -1.3479], grad_fn=<SubBackward0>)\n",
      "tensor(-2.0679, grad_fn=<NegBackward0>)\n",
      "tensor([0.4166, 0.4090, 0.4110, 0.4093, 0.4223], grad_fn=<SqueezeBackward3>) tensor([-0.9705, -5.6017, -7.0315, -3.8834, -1.3473], grad_fn=<SubBackward0>)\n",
      "tensor(-2.0682, grad_fn=<NegBackward0>)\n",
      "tensor([0.4167, 0.4090, 0.4110, 0.4094, 0.4224], grad_fn=<SqueezeBackward3>) tensor([-0.9708, -5.6009, -7.0316, -3.8829, -1.3466], grad_fn=<SubBackward0>)\n",
      "tensor(-2.0686, grad_fn=<NegBackward0>)\n",
      "tensor([0.4168, 0.4091, 0.4111, 0.4095, 0.4225], grad_fn=<SqueezeBackward3>) tensor([-0.9712, -5.6001, -7.0318, -3.8824, -1.3459], grad_fn=<SubBackward0>)\n",
      "tensor(-2.0689, grad_fn=<NegBackward0>)\n",
      "tensor([0.4169, 0.4092, 0.4111, 0.4095, 0.4226], grad_fn=<SqueezeBackward3>) tensor([-0.9715, -5.5992, -7.0320, -3.8818, -1.3452], grad_fn=<SubBackward0>)\n",
      "tensor(-2.0693, grad_fn=<NegBackward0>)\n",
      "tensor([0.4169, 0.4092, 0.4112, 0.4096, 0.4227], grad_fn=<SqueezeBackward3>) tensor([-0.9718, -5.5984, -7.0322, -3.8813, -1.3444], grad_fn=<SubBackward0>)\n",
      "tensor(-2.0696, grad_fn=<NegBackward0>)\n",
      "tensor([0.4170, 0.4093, 0.4113, 0.4097, 0.4228], grad_fn=<SqueezeBackward3>) tensor([-0.9721, -5.5975, -7.0323, -3.8808, -1.3437], grad_fn=<SubBackward0>)\n",
      "tensor(-2.0700, grad_fn=<NegBackward0>)\n",
      "tensor([0.4171, 0.4093, 0.4113, 0.4097, 0.4228], grad_fn=<SqueezeBackward3>) tensor([-0.9725, -5.5967, -7.0325, -3.8803, -1.3429], grad_fn=<SubBackward0>)\n",
      "tensor(-2.0703, grad_fn=<NegBackward0>)\n",
      "tensor([0.4172, 0.4094, 0.4114, 0.4098, 0.4229], grad_fn=<SqueezeBackward3>) tensor([-0.9728, -5.5958, -7.0327, -3.8797, -1.3420], grad_fn=<SubBackward0>)\n",
      "tensor(-2.0707, grad_fn=<NegBackward0>)\n",
      "tensor([0.4173, 0.4095, 0.4114, 0.4099, 0.4230], grad_fn=<SqueezeBackward3>) tensor([-0.9731, -5.5950, -7.0328, -3.8792, -1.3412], grad_fn=<SubBackward0>)\n",
      "tensor(-2.0710, grad_fn=<NegBackward0>)\n",
      "tensor([0.4173, 0.4095, 0.4115, 0.4099, 0.4231], grad_fn=<SqueezeBackward3>) tensor([-0.9734, -5.5941, -7.0330, -3.8787, -1.3403], grad_fn=<SubBackward0>)\n",
      "tensor(-2.0714, grad_fn=<NegBackward0>)\n",
      "tensor([0.4174, 0.4096, 0.4116, 0.4100, 0.4232], grad_fn=<SqueezeBackward3>) tensor([-0.9737, -5.5933, -7.0331, -3.8782, -1.3394], grad_fn=<SubBackward0>)\n",
      "tensor(-2.0717, grad_fn=<NegBackward0>)\n",
      "tensor([0.4175, 0.4097, 0.4116, 0.4100, 0.4233], grad_fn=<SqueezeBackward3>) tensor([-0.9740, -5.5924, -7.0333, -3.8776, -1.3385], grad_fn=<SubBackward0>)\n",
      "tensor(-2.0721, grad_fn=<NegBackward0>)\n",
      "tensor([0.4176, 0.4097, 0.4117, 0.4101, 0.4234], grad_fn=<SqueezeBackward3>) tensor([-0.9744, -5.5916, -7.0335, -3.8771, -1.3376], grad_fn=<SubBackward0>)\n",
      "tensor(-2.0724, grad_fn=<NegBackward0>)\n",
      "tensor([0.4177, 0.4098, 0.4117, 0.4102, 0.4234], grad_fn=<SqueezeBackward3>) tensor([-0.9747, -5.5907, -7.0336, -3.8766, -1.3367], grad_fn=<SubBackward0>)\n",
      "tensor(-2.0728, grad_fn=<NegBackward0>)\n",
      "tensor([0.4177, 0.4098, 0.4118, 0.4102, 0.4235], grad_fn=<SqueezeBackward3>) tensor([-0.9750, -5.5898, -7.0338, -3.8760, -1.3357], grad_fn=<SubBackward0>)\n",
      "tensor(-2.0731, grad_fn=<NegBackward0>)\n",
      "tensor([0.4178, 0.4099, 0.4119, 0.4103, 0.4236], grad_fn=<SqueezeBackward3>) tensor([-0.9753, -5.5890, -7.0339, -3.8755, -1.3348], grad_fn=<SubBackward0>)\n",
      "tensor(-2.0735, grad_fn=<NegBackward0>)\n",
      "tensor([0.4179, 0.4100, 0.4119, 0.4104, 0.4237], grad_fn=<SqueezeBackward3>) tensor([-0.9756, -5.5881, -7.0341, -3.8750, -1.3338], grad_fn=<SubBackward0>)\n",
      "tensor(-2.0738, grad_fn=<NegBackward0>)\n",
      "tensor([0.4180, 0.4100, 0.4120, 0.4104, 0.4238], grad_fn=<SqueezeBackward3>) tensor([-0.9759, -5.5873, -7.0342, -3.8745, -1.3328], grad_fn=<SubBackward0>)\n",
      "tensor(-2.0742, grad_fn=<NegBackward0>)\n",
      "tensor([0.4181, 0.4101, 0.4120, 0.4105, 0.4239], grad_fn=<SqueezeBackward3>) tensor([-0.9762, -5.5864, -7.0344, -3.8739, -1.3318], grad_fn=<SubBackward0>)\n",
      "tensor(-2.0745, grad_fn=<NegBackward0>)\n",
      "tensor([0.4181, 0.4102, 0.4121, 0.4106, 0.4240], grad_fn=<SqueezeBackward3>) tensor([-0.9764, -5.5856, -7.0345, -3.8734, -1.3307], grad_fn=<SubBackward0>)\n",
      "tensor(-2.0749, grad_fn=<NegBackward0>)\n",
      "tensor([0.4182, 0.4102, 0.4122, 0.4106, 0.4240], grad_fn=<SqueezeBackward3>) tensor([-0.9767, -5.5847, -7.0347, -3.8729, -1.3297], grad_fn=<SubBackward0>)\n",
      "tensor(-2.0753, grad_fn=<NegBackward0>)\n",
      "tensor([0.4183, 0.4103, 0.4122, 0.4107, 0.4241], grad_fn=<SqueezeBackward3>) tensor([-0.9770, -5.5838, -7.0348, -3.8723, -1.3287], grad_fn=<SubBackward0>)\n",
      "tensor(-2.0756, grad_fn=<NegBackward0>)\n",
      "tensor([0.4184, 0.4103, 0.4123, 0.4108, 0.4242], grad_fn=<SqueezeBackward3>) tensor([-0.9773, -5.5830, -7.0349, -3.8718, -1.3276], grad_fn=<SubBackward0>)\n",
      "tensor(-2.0760, grad_fn=<NegBackward0>)\n",
      "tensor([0.4185, 0.4104, 0.4123, 0.4108, 0.4243], grad_fn=<SqueezeBackward3>) tensor([-0.9776, -5.5821, -7.0351, -3.8712, -1.3266], grad_fn=<SubBackward0>)\n",
      "tensor(-2.0763, grad_fn=<NegBackward0>)\n",
      "tensor([0.4185, 0.4105, 0.4124, 0.4109, 0.4244], grad_fn=<SqueezeBackward3>) tensor([-0.9778, -5.5812, -7.0352, -3.8707, -1.3255], grad_fn=<SubBackward0>)\n",
      "tensor(-2.0767, grad_fn=<NegBackward0>)\n",
      "tensor([0.4186, 0.4105, 0.4125, 0.4109, 0.4245], grad_fn=<SqueezeBackward3>) tensor([-0.9781, -5.5804, -7.0353, -3.8702, -1.3244], grad_fn=<SubBackward0>)\n",
      "tensor(-2.0770, grad_fn=<NegBackward0>)\n",
      "tensor([0.4187, 0.4106, 0.4125, 0.4110, 0.4246], grad_fn=<SqueezeBackward3>) tensor([-0.9784, -5.5795, -7.0355, -3.8696, -1.3233], grad_fn=<SubBackward0>)\n",
      "tensor(-2.0774, grad_fn=<NegBackward0>)\n",
      "tensor([0.4188, 0.4106, 0.4126, 0.4111, 0.4246], grad_fn=<SqueezeBackward3>) tensor([-0.9787, -5.5786, -7.0356, -3.8691, -1.3222], grad_fn=<SubBackward0>)\n",
      "tensor(-2.0777, grad_fn=<NegBackward0>)\n",
      "tensor([0.4189, 0.4107, 0.4126, 0.4111, 0.4247], grad_fn=<SqueezeBackward3>) tensor([-0.9789, -5.5778, -7.0357, -3.8686, -1.3211], grad_fn=<SubBackward0>)\n",
      "tensor(-2.0781, grad_fn=<NegBackward0>)\n",
      "tensor([0.4189, 0.4108, 0.4127, 0.4112, 0.4248], grad_fn=<SqueezeBackward3>) tensor([-0.9792, -5.5769, -7.0358, -3.8680, -1.3200], grad_fn=<SubBackward0>)\n",
      "tensor(-2.0784, grad_fn=<NegBackward0>)\n",
      "tensor([0.4190, 0.4108, 0.4128, 0.4113, 0.4249], grad_fn=<SqueezeBackward3>) tensor([-0.9794, -5.5760, -7.0360, -3.8675, -1.3189], grad_fn=<SubBackward0>)\n",
      "tensor(-2.0788, grad_fn=<NegBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.4191, 0.4109, 0.4128, 0.4113, 0.4250], grad_fn=<SqueezeBackward3>) tensor([-0.9797, -5.5752, -7.0361, -3.8669, -1.3178], grad_fn=<SubBackward0>)\n",
      "tensor(-2.0791, grad_fn=<NegBackward0>)\n",
      "tensor([0.4192, 0.4110, 0.4129, 0.4114, 0.4251], grad_fn=<SqueezeBackward3>) tensor([-0.9799, -5.5743, -7.0362, -3.8664, -1.3167], grad_fn=<SubBackward0>)\n",
      "tensor(-2.0795, grad_fn=<NegBackward0>)\n",
      "tensor([0.4193, 0.4110, 0.4129, 0.4115, 0.4252], grad_fn=<SqueezeBackward3>) tensor([-0.9802, -5.5734, -7.0363, -3.8658, -1.3156], grad_fn=<SubBackward0>)\n",
      "tensor(-2.0798, grad_fn=<NegBackward0>)\n",
      "tensor([0.4193, 0.4111, 0.4130, 0.4115, 0.4252], grad_fn=<SqueezeBackward3>) tensor([-0.9804, -5.5726, -7.0364, -3.8653, -1.3144], grad_fn=<SubBackward0>)\n",
      "tensor(-2.0802, grad_fn=<NegBackward0>)\n",
      "tensor([0.4194, 0.4111, 0.4131, 0.4116, 0.4253], grad_fn=<SqueezeBackward3>) tensor([-0.9807, -5.5717, -7.0366, -3.8647, -1.3133], grad_fn=<SubBackward0>)\n",
      "tensor(-2.0805, grad_fn=<NegBackward0>)\n",
      "tensor([0.4195, 0.4112, 0.4131, 0.4117, 0.4254], grad_fn=<SqueezeBackward3>) tensor([-0.9809, -5.5708, -7.0367, -3.8642, -1.3122], grad_fn=<SubBackward0>)\n",
      "tensor(-2.0809, grad_fn=<NegBackward0>)\n",
      "tensor([0.4196, 0.4113, 0.4132, 0.4117, 0.4255], grad_fn=<SqueezeBackward3>) tensor([-0.9811, -5.5699, -7.0368, -3.8637, -1.3110], grad_fn=<SubBackward0>)\n",
      "tensor(-2.0812, grad_fn=<NegBackward0>)\n",
      "tensor([0.4197, 0.4113, 0.4132, 0.4118, 0.4256], grad_fn=<SqueezeBackward3>) tensor([-0.9814, -5.5691, -7.0369, -3.8631, -1.3099], grad_fn=<SubBackward0>)\n",
      "tensor(-2.0816, grad_fn=<NegBackward0>)\n",
      "tensor([0.4197, 0.4114, 0.4133, 0.4118, 0.4257], grad_fn=<SqueezeBackward3>) tensor([-0.9816, -5.5682, -7.0370, -3.8626, -1.3087], grad_fn=<SubBackward0>)\n",
      "tensor(-2.0819, grad_fn=<NegBackward0>)\n",
      "tensor([0.4198, 0.4115, 0.4134, 0.4119, 0.4258], grad_fn=<SqueezeBackward3>) tensor([-0.9818, -5.5673, -7.0371, -3.8620, -1.3076], grad_fn=<SubBackward0>)\n",
      "tensor(-2.0823, grad_fn=<NegBackward0>)\n",
      "tensor([0.4199, 0.4115, 0.4134, 0.4120, 0.4259], grad_fn=<SqueezeBackward3>) tensor([-0.9820, -5.5664, -7.0372, -3.8614, -1.3064], grad_fn=<SubBackward0>)\n",
      "tensor(-2.0827, grad_fn=<NegBackward0>)\n",
      "tensor([0.4200, 0.4116, 0.4135, 0.4120, 0.4259], grad_fn=<SqueezeBackward3>) tensor([-0.9823, -5.5655, -7.0373, -3.8609, -1.3053], grad_fn=<SubBackward0>)\n",
      "tensor(-2.0830, grad_fn=<NegBackward0>)\n",
      "tensor([0.4201, 0.4116, 0.4135, 0.4121, 0.4260], grad_fn=<SqueezeBackward3>) tensor([-0.9825, -5.5647, -7.0374, -3.8603, -1.3041], grad_fn=<SubBackward0>)\n",
      "tensor(-2.0834, grad_fn=<NegBackward0>)\n",
      "tensor([0.4201, 0.4117, 0.4136, 0.4122, 0.4261], grad_fn=<SqueezeBackward3>) tensor([-0.9827, -5.5638, -7.0375, -3.8598, -1.3030], grad_fn=<SubBackward0>)\n",
      "tensor(-2.0837, grad_fn=<NegBackward0>)\n",
      "tensor([0.4202, 0.4118, 0.4137, 0.4122, 0.4262], grad_fn=<SqueezeBackward3>) tensor([-0.9829, -5.5629, -7.0376, -3.8592, -1.3018], grad_fn=<SubBackward0>)\n",
      "tensor(-2.0841, grad_fn=<NegBackward0>)\n",
      "tensor([0.4203, 0.4118, 0.4137, 0.4123, 0.4263], grad_fn=<SqueezeBackward3>) tensor([-0.9831, -5.5620, -7.0377, -3.8587, -1.3006], grad_fn=<SubBackward0>)\n",
      "tensor(-2.0844, grad_fn=<NegBackward0>)\n",
      "tensor([0.4204, 0.4119, 0.4138, 0.4124, 0.4264], grad_fn=<SqueezeBackward3>) tensor([-0.9833, -5.5611, -7.0378, -3.8581, -1.2995], grad_fn=<SubBackward0>)\n",
      "tensor(-2.0848, grad_fn=<NegBackward0>)\n",
      "tensor([0.4205, 0.4119, 0.4138, 0.4124, 0.4265], grad_fn=<SqueezeBackward3>) tensor([-0.9835, -5.5602, -7.0378, -3.8576, -1.2983], grad_fn=<SubBackward0>)\n",
      "tensor(-2.0851, grad_fn=<NegBackward0>)\n",
      "tensor([0.4205, 0.4120, 0.4139, 0.4125, 0.4265], grad_fn=<SqueezeBackward3>) tensor([-0.9837, -5.5594, -7.0379, -3.8570, -1.2972], grad_fn=<SubBackward0>)\n",
      "tensor(-2.0855, grad_fn=<NegBackward0>)\n",
      "tensor([0.4206, 0.4121, 0.4140, 0.4126, 0.4266], grad_fn=<SqueezeBackward3>) tensor([-0.9839, -5.5585, -7.0380, -3.8564, -1.2960], grad_fn=<SubBackward0>)\n",
      "tensor(-2.0858, grad_fn=<NegBackward0>)\n",
      "tensor([0.4207, 0.4121, 0.4140, 0.4126, 0.4267], grad_fn=<SqueezeBackward3>) tensor([-0.9840, -5.5576, -7.0381, -3.8559, -1.2948], grad_fn=<SubBackward0>)\n",
      "tensor(-2.0862, grad_fn=<NegBackward0>)\n",
      "tensor([0.4208, 0.4122, 0.4141, 0.4127, 0.4268], grad_fn=<SqueezeBackward3>) tensor([-0.9842, -5.5567, -7.0382, -3.8553, -1.2937], grad_fn=<SubBackward0>)\n",
      "tensor(-2.0865, grad_fn=<NegBackward0>)\n",
      "tensor([0.4209, 0.4123, 0.4141, 0.4127, 0.4269], grad_fn=<SqueezeBackward3>) tensor([-0.9844, -5.5558, -7.0382, -3.8548, -1.2925], grad_fn=<SubBackward0>)\n",
      "tensor(-2.0869, grad_fn=<NegBackward0>)\n",
      "tensor([0.4209, 0.4123, 0.4142, 0.4128, 0.4270], grad_fn=<SqueezeBackward3>) tensor([-0.9846, -5.5549, -7.0383, -3.8542, -1.2913], grad_fn=<SubBackward0>)\n",
      "tensor(-2.0873, grad_fn=<NegBackward0>)\n",
      "tensor([0.4210, 0.4124, 0.4143, 0.4129, 0.4271], grad_fn=<SqueezeBackward3>) tensor([-0.9847, -5.5540, -7.0384, -3.8536, -1.2902], grad_fn=<SubBackward0>)\n",
      "tensor(-2.0876, grad_fn=<NegBackward0>)\n",
      "tensor([0.4211, 0.4124, 0.4143, 0.4129, 0.4272], grad_fn=<SqueezeBackward3>) tensor([-0.9849, -5.5531, -7.0385, -3.8531, -1.2890], grad_fn=<SubBackward0>)\n",
      "tensor(-2.0880, grad_fn=<NegBackward0>)\n",
      "tensor([0.4212, 0.4125, 0.4144, 0.4130, 0.4272], grad_fn=<SqueezeBackward3>) tensor([-0.9851, -5.5522, -7.0385, -3.8525, -1.2878], grad_fn=<SubBackward0>)\n",
      "tensor(-2.0883, grad_fn=<NegBackward0>)\n",
      "tensor([0.4213, 0.4126, 0.4144, 0.4131, 0.4273], grad_fn=<SqueezeBackward3>) tensor([-0.9852, -5.5513, -7.0386, -3.8519, -1.2866], grad_fn=<SubBackward0>)\n",
      "tensor(-2.0887, grad_fn=<NegBackward0>)\n",
      "tensor([0.4213, 0.4126, 0.4145, 0.4131, 0.4274], grad_fn=<SqueezeBackward3>) tensor([-0.9854, -5.5504, -7.0387, -3.8514, -1.2855], grad_fn=<SubBackward0>)\n",
      "tensor(-2.0890, grad_fn=<NegBackward0>)\n",
      "tensor([0.4214, 0.4127, 0.4146, 0.4132, 0.4275], grad_fn=<SqueezeBackward3>) tensor([-0.9855, -5.5496, -7.0387, -3.8508, -1.2843], grad_fn=<SubBackward0>)\n",
      "tensor(-2.0894, grad_fn=<NegBackward0>)\n",
      "tensor([0.4215, 0.4128, 0.4146, 0.4133, 0.4276], grad_fn=<SqueezeBackward3>) tensor([-0.9857, -5.5487, -7.0388, -3.8502, -1.2831], grad_fn=<SubBackward0>)\n",
      "tensor(-2.0897, grad_fn=<NegBackward0>)\n",
      "tensor([0.4216, 0.4128, 0.4147, 0.4133, 0.4277], grad_fn=<SqueezeBackward3>) tensor([-0.9858, -5.5478, -7.0388, -3.8497, -1.2820], grad_fn=<SubBackward0>)\n",
      "tensor(-2.0901, grad_fn=<NegBackward0>)\n",
      "tensor([0.4217, 0.4129, 0.4147, 0.4134, 0.4278], grad_fn=<SqueezeBackward3>) tensor([-0.9859, -5.5469, -7.0389, -3.8491, -1.2808], grad_fn=<SubBackward0>)\n",
      "tensor(-2.0904, grad_fn=<NegBackward0>)\n",
      "tensor([0.4217, 0.4129, 0.4148, 0.4134, 0.4279], grad_fn=<SqueezeBackward3>) tensor([-0.9861, -5.5460, -7.0389, -3.8485, -1.2796], grad_fn=<SubBackward0>)\n",
      "tensor(-2.0908, grad_fn=<NegBackward0>)\n",
      "tensor([0.4218, 0.4130, 0.4149, 0.4135, 0.4280], grad_fn=<SqueezeBackward3>) tensor([-0.9862, -5.5451, -7.0390, -3.8479, -1.2784], grad_fn=<SubBackward0>)\n",
      "tensor(-2.0911, grad_fn=<NegBackward0>)\n",
      "tensor([0.4219, 0.4131, 0.4149, 0.4136, 0.4280], grad_fn=<SqueezeBackward3>) tensor([-0.9863, -5.5442, -7.0390, -3.8474, -1.2773], grad_fn=<SubBackward0>)\n",
      "tensor(-2.0915, grad_fn=<NegBackward0>)\n",
      "tensor([0.4220, 0.4131, 0.4150, 0.4136, 0.4281], grad_fn=<SqueezeBackward3>) tensor([-0.9864, -5.5432, -7.0391, -3.8468, -1.2761], grad_fn=<SubBackward0>)\n",
      "tensor(-2.0919, grad_fn=<NegBackward0>)\n",
      "tensor([0.4221, 0.4132, 0.4150, 0.4137, 0.4282], grad_fn=<SqueezeBackward3>) tensor([-0.9865, -5.5423, -7.0391, -3.8462, -1.2749], grad_fn=<SubBackward0>)\n",
      "tensor(-2.0922, grad_fn=<NegBackward0>)\n",
      "tensor([0.4221, 0.4132, 0.4151, 0.4138, 0.4283], grad_fn=<SqueezeBackward3>) tensor([-0.9866, -5.5414, -7.0392, -3.8456, -1.2738], grad_fn=<SubBackward0>)\n",
      "tensor(-2.0926, grad_fn=<NegBackward0>)\n",
      "tensor([0.4222, 0.4133, 0.4152, 0.4138, 0.4284], grad_fn=<SqueezeBackward3>) tensor([-0.9867, -5.5405, -7.0392, -3.8451, -1.2726], grad_fn=<SubBackward0>)\n",
      "tensor(-2.0929, grad_fn=<NegBackward0>)\n",
      "tensor([0.4223, 0.4134, 0.4152, 0.4139, 0.4285], grad_fn=<SqueezeBackward3>) tensor([-0.9868, -5.5396, -7.0392, -3.8445, -1.2714], grad_fn=<SubBackward0>)\n",
      "tensor(-2.0933, grad_fn=<NegBackward0>)\n",
      "tensor([0.4224, 0.4134, 0.4153, 0.4140, 0.4286], grad_fn=<SqueezeBackward3>) tensor([-0.9869, -5.5387, -7.0393, -3.8439, -1.2703], grad_fn=<SubBackward0>)\n",
      "tensor(-2.0936, grad_fn=<NegBackward0>)\n",
      "tensor([0.4225, 0.4135, 0.4153, 0.4140, 0.4287], grad_fn=<SqueezeBackward3>) tensor([-0.9870, -5.5378, -7.0393, -3.8433, -1.2691], grad_fn=<SubBackward0>)\n",
      "tensor(-2.0940, grad_fn=<NegBackward0>)\n",
      "tensor([0.4225, 0.4136, 0.4154, 0.4141, 0.4287], grad_fn=<SqueezeBackward3>) tensor([-0.9871, -5.5369, -7.0393, -3.8427, -1.2679], grad_fn=<SubBackward0>)\n",
      "tensor(-2.0943, grad_fn=<NegBackward0>)\n",
      "tensor([0.4226, 0.4136, 0.4155, 0.4142, 0.4288], grad_fn=<SqueezeBackward3>) tensor([-0.9872, -5.5360, -7.0394, -3.8422, -1.2668], grad_fn=<SubBackward0>)\n",
      "tensor(-2.0947, grad_fn=<NegBackward0>)\n",
      "tensor([0.4227, 0.4137, 0.4155, 0.4142, 0.4289], grad_fn=<SqueezeBackward3>) tensor([-0.9873, -5.5351, -7.0394, -3.8416, -1.2656], grad_fn=<SubBackward0>)\n",
      "tensor(-2.0950, grad_fn=<NegBackward0>)\n",
      "tensor([0.4228, 0.4137, 0.4156, 0.4143, 0.4290], grad_fn=<SqueezeBackward3>) tensor([-0.9873, -5.5342, -7.0394, -3.8410, -1.2644], grad_fn=<SubBackward0>)\n",
      "tensor(-2.0954, grad_fn=<NegBackward0>)\n",
      "tensor([0.4229, 0.4138, 0.4156, 0.4143, 0.4291], grad_fn=<SqueezeBackward3>) tensor([-0.9874, -5.5332, -7.0394, -3.8404, -1.2633], grad_fn=<SubBackward0>)\n",
      "tensor(-2.0958, grad_fn=<NegBackward0>)\n",
      "tensor([0.4229, 0.4139, 0.4157, 0.4144, 0.4292], grad_fn=<SqueezeBackward3>) tensor([-0.9875, -5.5323, -7.0395, -3.8398, -1.2621], grad_fn=<SubBackward0>)\n",
      "tensor(-2.0961, grad_fn=<NegBackward0>)\n",
      "tensor([0.4230, 0.4139, 0.4158, 0.4145, 0.4293], grad_fn=<SqueezeBackward3>) tensor([-0.9875, -5.5314, -7.0395, -3.8392, -1.2609], grad_fn=<SubBackward0>)\n",
      "tensor(-2.0965, grad_fn=<NegBackward0>)\n",
      "tensor([0.4231, 0.4140, 0.4158, 0.4145, 0.4294], grad_fn=<SqueezeBackward3>) tensor([-0.9876, -5.5305, -7.0395, -3.8386, -1.2598], grad_fn=<SubBackward0>)\n",
      "tensor(-2.0968, grad_fn=<NegBackward0>)\n",
      "tensor([0.4232, 0.4141, 0.4159, 0.4146, 0.4295], grad_fn=<SqueezeBackward3>) tensor([-0.9876, -5.5296, -7.0395, -3.8380, -1.2586], grad_fn=<SubBackward0>)\n",
      "tensor(-2.0972, grad_fn=<NegBackward0>)\n",
      "tensor([0.4233, 0.4141, 0.4159, 0.4147, 0.4295], grad_fn=<SqueezeBackward3>) tensor([-0.9876, -5.5287, -7.0395, -3.8375, -1.2574], grad_fn=<SubBackward0>)\n",
      "tensor(-2.0975, grad_fn=<NegBackward0>)\n",
      "tensor([0.4233, 0.4142, 0.4160, 0.4147, 0.4296], grad_fn=<SqueezeBackward3>) tensor([-0.9877, -5.5277, -7.0395, -3.8369, -1.2563], grad_fn=<SubBackward0>)\n",
      "tensor(-2.0979, grad_fn=<NegBackward0>)\n",
      "tensor([0.4234, 0.4142, 0.4161, 0.4148, 0.4297], grad_fn=<SqueezeBackward3>) tensor([-0.9877, -5.5268, -7.0395, -3.8363, -1.2551], grad_fn=<SubBackward0>)\n",
      "tensor(-2.0982, grad_fn=<NegBackward0>)\n",
      "tensor([0.4235, 0.4143, 0.4161, 0.4149, 0.4298], grad_fn=<SqueezeBackward3>) tensor([-0.9877, -5.5259, -7.0395, -3.8357, -1.2539], grad_fn=<SubBackward0>)\n",
      "tensor(-2.0986, grad_fn=<NegBackward0>)\n",
      "tensor([0.4236, 0.4144, 0.4162, 0.4149, 0.4299], grad_fn=<SqueezeBackward3>) tensor([-0.9878, -5.5250, -7.0395, -3.8351, -1.2528], grad_fn=<SubBackward0>)\n",
      "tensor(-2.0990, grad_fn=<NegBackward0>)\n",
      "tensor([0.4237, 0.4144, 0.4162, 0.4150, 0.4300], grad_fn=<SqueezeBackward3>) tensor([-0.9878, -5.5240, -7.0395, -3.8345, -1.2516], grad_fn=<SubBackward0>)\n",
      "tensor(-2.0993, grad_fn=<NegBackward0>)\n",
      "tensor([0.4238, 0.4145, 0.4163, 0.4151, 0.4301], grad_fn=<SqueezeBackward3>) tensor([-0.9878, -5.5231, -7.0395, -3.8339, -1.2505], grad_fn=<SubBackward0>)\n",
      "tensor(-2.0997, grad_fn=<NegBackward0>)\n",
      "tensor([0.4238, 0.4145, 0.4164, 0.4151, 0.4302], grad_fn=<SqueezeBackward3>) tensor([-0.9878, -5.5222, -7.0395, -3.8333, -1.2493], grad_fn=<SubBackward0>)\n",
      "tensor(-2.1000, grad_fn=<NegBackward0>)\n",
      "tensor([0.4239, 0.4146, 0.4164, 0.4152, 0.4303], grad_fn=<SqueezeBackward3>) tensor([-0.9878, -5.5213, -7.0395, -3.8327, -1.2481], grad_fn=<SubBackward0>)\n",
      "tensor(-2.1004, grad_fn=<NegBackward0>)\n",
      "tensor([0.4240, 0.4147, 0.4165, 0.4152, 0.4303], grad_fn=<SqueezeBackward3>) tensor([-0.9878, -5.5203, -7.0395, -3.8321, -1.2470], grad_fn=<SubBackward0>)\n",
      "tensor(-2.1007, grad_fn=<NegBackward0>)\n",
      "tensor([0.4241, 0.4147, 0.4165, 0.4153, 0.4304], grad_fn=<SqueezeBackward3>) tensor([-0.9877, -5.5194, -7.0395, -3.8315, -1.2458], grad_fn=<SubBackward0>)\n",
      "tensor(-2.1011, grad_fn=<NegBackward0>)\n",
      "tensor([0.4242, 0.4148, 0.4166, 0.4154, 0.4305], grad_fn=<SqueezeBackward3>) tensor([-0.9877, -5.5185, -7.0395, -3.8309, -1.2447], grad_fn=<SubBackward0>)\n",
      "tensor(-2.1015, grad_fn=<NegBackward0>)\n",
      "tensor([0.4242, 0.4149, 0.4167, 0.4154, 0.4306], grad_fn=<SqueezeBackward3>) tensor([-0.9877, -5.5175, -7.0394, -3.8303, -1.2435], grad_fn=<SubBackward0>)\n",
      "tensor(-2.1018, grad_fn=<NegBackward0>)\n",
      "tensor([0.4243, 0.4149, 0.4167, 0.4155, 0.4307], grad_fn=<SqueezeBackward3>) tensor([-0.9877, -5.5166, -7.0394, -3.8297, -1.2424], grad_fn=<SubBackward0>)\n",
      "tensor(-2.1022, grad_fn=<NegBackward0>)\n",
      "tensor([0.4244, 0.4150, 0.4168, 0.4156, 0.4308], grad_fn=<SqueezeBackward3>) tensor([-0.9876, -5.5157, -7.0394, -3.8291, -1.2412], grad_fn=<SubBackward0>)\n",
      "tensor(-2.1025, grad_fn=<NegBackward0>)\n",
      "tensor([0.4245, 0.4150, 0.4168, 0.4156, 0.4309], grad_fn=<SqueezeBackward3>) tensor([-0.9876, -5.5147, -7.0394, -3.8285, -1.2401], grad_fn=<SubBackward0>)\n",
      "tensor(-2.1029, grad_fn=<NegBackward0>)\n",
      "tensor([0.4246, 0.4151, 0.4169, 0.4157, 0.4310], grad_fn=<SqueezeBackward3>) tensor([-0.9875, -5.5138, -7.0393, -3.8279, -1.2389], grad_fn=<SubBackward0>)\n",
      "tensor(-2.1032, grad_fn=<NegBackward0>)\n",
      "tensor([0.4246, 0.4152, 0.4170, 0.4158, 0.4311], grad_fn=<SqueezeBackward3>) tensor([-0.9875, -5.5129, -7.0393, -3.8273, -1.2378], grad_fn=<SubBackward0>)\n",
      "tensor(-2.1036, grad_fn=<NegBackward0>)\n",
      "tensor([0.4247, 0.4152, 0.4170, 0.4158, 0.4312], grad_fn=<SqueezeBackward3>) tensor([-0.9874, -5.5119, -7.0393, -3.8266, -1.2366], grad_fn=<SubBackward0>)\n",
      "tensor(-2.1039, grad_fn=<NegBackward0>)\n",
      "tensor([0.4248, 0.4153, 0.4171, 0.4159, 0.4312], grad_fn=<SqueezeBackward3>) tensor([-0.9874, -5.5110, -7.0392, -3.8260, -1.2355], grad_fn=<SubBackward0>)\n",
      "tensor(-2.1043, grad_fn=<NegBackward0>)\n",
      "tensor([0.4249, 0.4154, 0.4171, 0.4160, 0.4313], grad_fn=<SqueezeBackward3>) tensor([-0.9873, -5.5100, -7.0392, -3.8254, -1.2343], grad_fn=<SubBackward0>)\n",
      "tensor(-2.1047, grad_fn=<NegBackward0>)\n",
      "tensor([0.4250, 0.4154, 0.4172, 0.4160, 0.4314], grad_fn=<SqueezeBackward3>) tensor([-0.9872, -5.5091, -7.0391, -3.8248, -1.2332], grad_fn=<SubBackward0>)\n",
      "tensor(-2.1050, grad_fn=<NegBackward0>)\n",
      "tensor([0.4250, 0.4155, 0.4173, 0.4161, 0.4315], grad_fn=<SqueezeBackward3>) tensor([-0.9871, -5.5082, -7.0391, -3.8242, -1.2320], grad_fn=<SubBackward0>)\n",
      "tensor(-2.1054, grad_fn=<NegBackward0>)\n",
      "tensor([0.4251, 0.4155, 0.4173, 0.4161, 0.4316], grad_fn=<SqueezeBackward3>) tensor([-0.9870, -5.5072, -7.0391, -3.8236, -1.2309], grad_fn=<SubBackward0>)\n",
      "tensor(-2.1057, grad_fn=<NegBackward0>)\n",
      "tensor([0.4252, 0.4156, 0.4174, 0.4162, 0.4317], grad_fn=<SqueezeBackward3>) tensor([-0.9869, -5.5063, -7.0390, -3.8230, -1.2297], grad_fn=<SubBackward0>)\n",
      "tensor(-2.1061, grad_fn=<NegBackward0>)\n",
      "tensor([0.4253, 0.4157, 0.4174, 0.4163, 0.4318], grad_fn=<SqueezeBackward3>) tensor([-0.9868, -5.5053, -7.0390, -3.8224, -1.2286], grad_fn=<SubBackward0>)\n",
      "tensor(-2.1064, grad_fn=<NegBackward0>)\n",
      "tensor([0.4254, 0.4157, 0.4175, 0.4163, 0.4319], grad_fn=<SqueezeBackward3>) tensor([-0.9867, -5.5044, -7.0389, -3.8217, -1.2274], grad_fn=<SubBackward0>)\n",
      "tensor(-2.1068, grad_fn=<NegBackward0>)\n",
      "tensor([0.4254, 0.4158, 0.4176, 0.4164, 0.4320], grad_fn=<SqueezeBackward3>) tensor([-0.9866, -5.5034, -7.0388, -3.8211, -1.2263], grad_fn=<SubBackward0>)\n",
      "tensor(-2.1072, grad_fn=<NegBackward0>)\n",
      "tensor([0.4255, 0.4158, 0.4176, 0.4165, 0.4321], grad_fn=<SqueezeBackward3>) tensor([-0.9865, -5.5025, -7.0388, -3.8205, -1.2251], grad_fn=<SubBackward0>)\n",
      "tensor(-2.1075, grad_fn=<NegBackward0>)\n",
      "tensor([0.4256, 0.4159, 0.4177, 0.4165, 0.4321], grad_fn=<SqueezeBackward3>) tensor([-0.9864, -5.5015, -7.0387, -3.8199, -1.2240], grad_fn=<SubBackward0>)\n",
      "tensor(-2.1079, grad_fn=<NegBackward0>)\n",
      "tensor([0.4257, 0.4160, 0.4177, 0.4166, 0.4322], grad_fn=<SqueezeBackward3>) tensor([-0.9862, -5.5006, -7.0386, -3.8192, -1.2229], grad_fn=<SubBackward0>)\n",
      "tensor(-2.1082, grad_fn=<NegBackward0>)\n",
      "tensor([0.4258, 0.4160, 0.4178, 0.4167, 0.4323], grad_fn=<SqueezeBackward3>) tensor([-0.9861, -5.4996, -7.0386, -3.8186, -1.2217], grad_fn=<SubBackward0>)\n",
      "tensor(-2.1086, grad_fn=<NegBackward0>)\n",
      "tensor([0.4259, 0.4161, 0.4179, 0.4167, 0.4324], grad_fn=<SqueezeBackward3>) tensor([-0.9859, -5.4987, -7.0385, -3.8180, -1.2206], grad_fn=<SubBackward0>)\n",
      "tensor(-2.1090, grad_fn=<NegBackward0>)\n",
      "tensor([0.4259, 0.4162, 0.4179, 0.4168, 0.4325], grad_fn=<SqueezeBackward3>) tensor([-0.9858, -5.4977, -7.0384, -3.8174, -1.2194], grad_fn=<SubBackward0>)\n",
      "tensor(-2.1093, grad_fn=<NegBackward0>)\n",
      "tensor([0.4260, 0.4162, 0.4180, 0.4168, 0.4326], grad_fn=<SqueezeBackward3>) tensor([-0.9856, -5.4968, -7.0384, -3.8167, -1.2183], grad_fn=<SubBackward0>)\n",
      "tensor(-2.1097, grad_fn=<NegBackward0>)\n",
      "tensor([0.4261, 0.4163, 0.4180, 0.4169, 0.4327], grad_fn=<SqueezeBackward3>) tensor([-0.9855, -5.4958, -7.0383, -3.8161, -1.2172], grad_fn=<SubBackward0>)\n",
      "tensor(-2.1100, grad_fn=<NegBackward0>)\n",
      "tensor([0.4262, 0.4163, 0.4181, 0.4170, 0.4328], grad_fn=<SqueezeBackward3>) tensor([-0.9853, -5.4948, -7.0382, -3.8155, -1.2160], grad_fn=<SubBackward0>)\n",
      "tensor(-2.1104, grad_fn=<NegBackward0>)\n",
      "tensor([0.4263, 0.4164, 0.4182, 0.4170, 0.4329], grad_fn=<SqueezeBackward3>) tensor([-0.9851, -5.4939, -7.0381, -3.8149, -1.2149], grad_fn=<SubBackward0>)\n",
      "tensor(-2.1107, grad_fn=<NegBackward0>)\n",
      "tensor([0.4263, 0.4165, 0.4182, 0.4171, 0.4330], grad_fn=<SqueezeBackward3>) tensor([-0.9849, -5.4929, -7.0380, -3.8142, -1.2138], grad_fn=<SubBackward0>)\n",
      "tensor(-2.1111, grad_fn=<NegBackward0>)\n",
      "tensor([0.4264, 0.4165, 0.4183, 0.4172, 0.4331], grad_fn=<SqueezeBackward3>) tensor([-0.9847, -5.4920, -7.0379, -3.8136, -1.2126], grad_fn=<SubBackward0>)\n",
      "tensor(-2.1115, grad_fn=<NegBackward0>)\n",
      "tensor([0.4265, 0.4166, 0.4183, 0.4172, 0.4331], grad_fn=<SqueezeBackward3>) tensor([-0.9845, -5.4910, -7.0378, -3.8130, -1.2115], grad_fn=<SubBackward0>)\n",
      "tensor(-2.1118, grad_fn=<NegBackward0>)\n",
      "tensor([0.4266, 0.4167, 0.4184, 0.4173, 0.4332], grad_fn=<SqueezeBackward3>) tensor([-0.9843, -5.4900, -7.0377, -3.8123, -1.2104], grad_fn=<SubBackward0>)\n",
      "tensor(-2.1122, grad_fn=<NegBackward0>)\n",
      "tensor([0.4267, 0.4167, 0.4185, 0.4174, 0.4333], grad_fn=<SqueezeBackward3>) tensor([-0.9841, -5.4891, -7.0376, -3.8117, -1.2092], grad_fn=<SubBackward0>)\n",
      "tensor(-2.1125, grad_fn=<NegBackward0>)\n",
      "tensor([0.4267, 0.4168, 0.4185, 0.4174, 0.4334], grad_fn=<SqueezeBackward3>) tensor([-0.9839, -5.4881, -7.0375, -3.8111, -1.2081], grad_fn=<SubBackward0>)\n",
      "tensor(-2.1129, grad_fn=<NegBackward0>)\n",
      "tensor([0.4268, 0.4168, 0.4186, 0.4175, 0.4335], grad_fn=<SqueezeBackward3>) tensor([-0.9836, -5.4871, -7.0374, -3.8104, -1.2070], grad_fn=<SubBackward0>)\n",
      "tensor(-2.1133, grad_fn=<NegBackward0>)\n",
      "tensor([0.4269, 0.4169, 0.4186, 0.4176, 0.4336], grad_fn=<SqueezeBackward3>) tensor([-0.9834, -5.4862, -7.0373, -3.8098, -1.2059], grad_fn=<SubBackward0>)\n",
      "tensor(-2.1136, grad_fn=<NegBackward0>)\n",
      "tensor([0.4270, 0.4170, 0.4187, 0.4176, 0.4337], grad_fn=<SqueezeBackward3>) tensor([-0.9832, -5.4852, -7.0372, -3.8091, -1.2047], grad_fn=<SubBackward0>)\n",
      "tensor(-2.1140, grad_fn=<NegBackward0>)\n",
      "tensor([0.4271, 0.4170, 0.4188, 0.4177, 0.4338], grad_fn=<SqueezeBackward3>) tensor([-0.9829, -5.4842, -7.0371, -3.8085, -1.2036], grad_fn=<SubBackward0>)\n",
      "tensor(-2.1143, grad_fn=<NegBackward0>)\n",
      "tensor([0.4271, 0.4171, 0.4188, 0.4177, 0.4339], grad_fn=<SqueezeBackward3>) tensor([-0.9827, -5.4832, -7.0370, -3.8078, -1.2025], grad_fn=<SubBackward0>)\n",
      "tensor(-2.1147, grad_fn=<NegBackward0>)\n",
      "tensor([0.4272, 0.4171, 0.4189, 0.4178, 0.4340], grad_fn=<SqueezeBackward3>) tensor([-0.9824, -5.4823, -7.0369, -3.8072, -1.2014], grad_fn=<SubBackward0>)\n",
      "tensor(-2.1150, grad_fn=<NegBackward0>)\n",
      "tensor([0.4273, 0.4172, 0.4189, 0.4179, 0.4341], grad_fn=<SqueezeBackward3>) tensor([-0.9821, -5.4813, -7.0368, -3.8066, -1.2002], grad_fn=<SubBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-2.1154, grad_fn=<NegBackward0>)\n",
      "tensor([0.4274, 0.4173, 0.4190, 0.4179, 0.4342], grad_fn=<SqueezeBackward3>) tensor([-0.9819, -5.4803, -7.0366, -3.8059, -1.1991], grad_fn=<SubBackward0>)\n",
      "tensor(-2.1158, grad_fn=<NegBackward0>)\n",
      "tensor([0.4275, 0.4173, 0.4191, 0.4180, 0.4342], grad_fn=<SqueezeBackward3>) tensor([-0.9816, -5.4793, -7.0365, -3.8053, -1.1980], grad_fn=<SubBackward0>)\n",
      "tensor(-2.1161, grad_fn=<NegBackward0>)\n",
      "tensor([0.4276, 0.4174, 0.4191, 0.4181, 0.4343], grad_fn=<SqueezeBackward3>) tensor([-0.9813, -5.4783, -7.0364, -3.8046, -1.1969], grad_fn=<SubBackward0>)\n",
      "tensor(-2.1165, grad_fn=<NegBackward0>)\n",
      "tensor([0.4276, 0.4175, 0.4192, 0.4181, 0.4344], grad_fn=<SqueezeBackward3>) tensor([-0.9810, -5.4774, -7.0363, -3.8040, -1.1958], grad_fn=<SubBackward0>)\n",
      "tensor(-2.1168, grad_fn=<NegBackward0>)\n",
      "tensor([0.4277, 0.4175, 0.4192, 0.4182, 0.4345], grad_fn=<SqueezeBackward3>) tensor([-0.9807, -5.4764, -7.0361, -3.8033, -1.1946], grad_fn=<SubBackward0>)\n",
      "tensor(-2.1172, grad_fn=<NegBackward0>)\n",
      "tensor([0.4278, 0.4176, 0.4193, 0.4183, 0.4346], grad_fn=<SqueezeBackward3>) tensor([-0.9804, -5.4754, -7.0360, -3.8027, -1.1935], grad_fn=<SubBackward0>)\n",
      "tensor(-2.1176, grad_fn=<NegBackward0>)\n",
      "tensor([0.4279, 0.4176, 0.4194, 0.4183, 0.4347], grad_fn=<SqueezeBackward3>) tensor([-0.9801, -5.4744, -7.0358, -3.8020, -1.1924], grad_fn=<SubBackward0>)\n",
      "tensor(-2.1179, grad_fn=<NegBackward0>)\n",
      "tensor([0.4280, 0.4177, 0.4194, 0.4184, 0.4348], grad_fn=<SqueezeBackward3>) tensor([-0.9797, -5.4734, -7.0357, -3.8013, -1.1913], grad_fn=<SubBackward0>)\n",
      "tensor(-2.1183, grad_fn=<NegBackward0>)\n",
      "tensor([0.4280, 0.4178, 0.4195, 0.4185, 0.4349], grad_fn=<SqueezeBackward3>) tensor([-0.9794, -5.4724, -7.0355, -3.8007, -1.1902], grad_fn=<SubBackward0>)\n",
      "tensor(-2.1186, grad_fn=<NegBackward0>)\n",
      "tensor([0.4281, 0.4178, 0.4195, 0.4185, 0.4350], grad_fn=<SqueezeBackward3>) tensor([-0.9791, -5.4715, -7.0354, -3.8000, -1.1891], grad_fn=<SubBackward0>)\n",
      "tensor(-2.1190, grad_fn=<NegBackward0>)\n",
      "tensor([0.4282, 0.4179, 0.4196, 0.4186, 0.4351], grad_fn=<SqueezeBackward3>) tensor([-0.9787, -5.4705, -7.0352, -3.7994, -1.1879], grad_fn=<SubBackward0>)\n",
      "tensor(-2.1194, grad_fn=<NegBackward0>)\n",
      "tensor([0.4283, 0.4180, 0.4197, 0.4186, 0.4352], grad_fn=<SqueezeBackward3>) tensor([-0.9784, -5.4695, -7.0351, -3.7987, -1.1868], grad_fn=<SubBackward0>)\n",
      "tensor(-2.1197, grad_fn=<NegBackward0>)\n",
      "tensor([0.4284, 0.4180, 0.4197, 0.4187, 0.4353], grad_fn=<SqueezeBackward3>) tensor([-0.9780, -5.4685, -7.0349, -3.7981, -1.1857], grad_fn=<SubBackward0>)\n",
      "tensor(-2.1201, grad_fn=<NegBackward0>)\n",
      "tensor([0.4285, 0.4181, 0.4198, 0.4188, 0.4354], grad_fn=<SqueezeBackward3>) tensor([-0.9776, -5.4675, -7.0348, -3.7974, -1.1846], grad_fn=<SubBackward0>)\n",
      "tensor(-2.1204, grad_fn=<NegBackward0>)\n",
      "tensor([0.4285, 0.4181, 0.4198, 0.4188, 0.4354], grad_fn=<SqueezeBackward3>) tensor([-0.9773, -5.4665, -7.0346, -3.7967, -1.1835], grad_fn=<SubBackward0>)\n",
      "tensor(-2.1208, grad_fn=<NegBackward0>)\n",
      "tensor([0.4286, 0.4182, 0.4199, 0.4189, 0.4355], grad_fn=<SqueezeBackward3>) tensor([-0.9769, -5.4655, -7.0344, -3.7961, -1.1824], grad_fn=<SubBackward0>)\n",
      "tensor(-2.1212, grad_fn=<NegBackward0>)\n",
      "tensor([0.4287, 0.4183, 0.4200, 0.4190, 0.4356], grad_fn=<SqueezeBackward3>) tensor([-0.9765, -5.4645, -7.0343, -3.7954, -1.1813], grad_fn=<SubBackward0>)\n",
      "tensor(-2.1215, grad_fn=<NegBackward0>)\n",
      "tensor([0.4288, 0.4183, 0.4200, 0.4190, 0.4357], grad_fn=<SqueezeBackward3>) tensor([-0.9761, -5.4635, -7.0341, -3.7947, -1.1802], grad_fn=<SubBackward0>)\n",
      "tensor(-2.1219, grad_fn=<NegBackward0>)\n",
      "tensor([0.4289, 0.4184, 0.4201, 0.4191, 0.4358], grad_fn=<SqueezeBackward3>) tensor([-0.9757, -5.4625, -7.0339, -3.7941, -1.1791], grad_fn=<SubBackward0>)\n",
      "tensor(-2.1223, grad_fn=<NegBackward0>)\n",
      "tensor([0.4289, 0.4184, 0.4201, 0.4192, 0.4359], grad_fn=<SqueezeBackward3>) tensor([-0.9753, -5.4615, -7.0337, -3.7934, -1.1780], grad_fn=<SubBackward0>)\n",
      "tensor(-2.1226, grad_fn=<NegBackward0>)\n",
      "tensor([0.4290, 0.4185, 0.4202, 0.4192, 0.4360], grad_fn=<SqueezeBackward3>) tensor([-0.9749, -5.4605, -7.0335, -3.7927, -1.1769], grad_fn=<SubBackward0>)\n",
      "tensor(-2.1230, grad_fn=<NegBackward0>)\n",
      "tensor([0.4291, 0.4186, 0.4203, 0.4193, 0.4361], grad_fn=<SqueezeBackward3>) tensor([-0.9744, -5.4595, -7.0334, -3.7920, -1.1758], grad_fn=<SubBackward0>)\n",
      "tensor(-2.1233, grad_fn=<NegBackward0>)\n",
      "tensor([0.4292, 0.4186, 0.4203, 0.4194, 0.4362], grad_fn=<SqueezeBackward3>) tensor([-0.9740, -5.4585, -7.0332, -3.7914, -1.1747], grad_fn=<SubBackward0>)\n",
      "tensor(-2.1237, grad_fn=<NegBackward0>)\n",
      "tensor([0.4293, 0.4187, 0.4204, 0.4194, 0.4363], grad_fn=<SqueezeBackward3>) tensor([-0.9736, -5.4575, -7.0330, -3.7907, -1.1736], grad_fn=<SubBackward0>)\n",
      "tensor(-2.1241, grad_fn=<NegBackward0>)\n",
      "tensor([0.4294, 0.4188, 0.4204, 0.4195, 0.4364], grad_fn=<SqueezeBackward3>) tensor([-0.9731, -5.4565, -7.0328, -3.7900, -1.1725], grad_fn=<SubBackward0>)\n",
      "tensor(-2.1244, grad_fn=<NegBackward0>)\n",
      "tensor([0.4294, 0.4188, 0.4205, 0.4195, 0.4365], grad_fn=<SqueezeBackward3>) tensor([-0.9727, -5.4555, -7.0326, -3.7893, -1.1714], grad_fn=<SubBackward0>)\n",
      "tensor(-2.1248, grad_fn=<NegBackward0>)\n",
      "tensor([0.4295, 0.4189, 0.4206, 0.4196, 0.4366], grad_fn=<SqueezeBackward3>) tensor([-0.9722, -5.4545, -7.0324, -3.7886, -1.1703], grad_fn=<SubBackward0>)\n",
      "tensor(-2.1251, grad_fn=<NegBackward0>)\n",
      "tensor([0.4296, 0.4189, 0.4206, 0.4197, 0.4367], grad_fn=<SqueezeBackward3>) tensor([-0.9717, -5.4534, -7.0322, -3.7880, -1.1692], grad_fn=<SubBackward0>)\n",
      "tensor(-2.1255, grad_fn=<NegBackward0>)\n",
      "tensor([0.4297, 0.4190, 0.4207, 0.4197, 0.4367], grad_fn=<SqueezeBackward3>) tensor([-0.9713, -5.4524, -7.0320, -3.7873, -1.1681], grad_fn=<SubBackward0>)\n",
      "tensor(-2.1259, grad_fn=<NegBackward0>)\n",
      "tensor([0.4298, 0.4191, 0.4208, 0.4198, 0.4368], grad_fn=<SqueezeBackward3>) tensor([-0.9708, -5.4514, -7.0318, -3.7866, -1.1670], grad_fn=<SubBackward0>)\n",
      "tensor(-2.1262, grad_fn=<NegBackward0>)\n",
      "tensor([0.4298, 0.4191, 0.4208, 0.4199, 0.4369], grad_fn=<SqueezeBackward3>) tensor([-0.9703, -5.4504, -7.0315, -3.7859, -1.1659], grad_fn=<SubBackward0>)\n",
      "tensor(-2.1266, grad_fn=<NegBackward0>)\n",
      "tensor([0.4299, 0.4192, 0.4209, 0.4199, 0.4370], grad_fn=<SqueezeBackward3>) tensor([-0.9698, -5.4494, -7.0313, -3.7852, -1.1648], grad_fn=<SubBackward0>)\n",
      "tensor(-2.1270, grad_fn=<NegBackward0>)\n",
      "tensor([0.4300, 0.4193, 0.4209, 0.4200, 0.4371], grad_fn=<SqueezeBackward3>) tensor([-0.9693, -5.4484, -7.0311, -3.7845, -1.1637], grad_fn=<SubBackward0>)\n",
      "tensor(-2.1273, grad_fn=<NegBackward0>)\n",
      "tensor([0.4301, 0.4193, 0.4210, 0.4201, 0.4372], grad_fn=<SqueezeBackward3>) tensor([-0.9688, -5.4473, -7.0309, -3.7838, -1.1626], grad_fn=<SubBackward0>)\n",
      "tensor(-2.1277, grad_fn=<NegBackward0>)\n",
      "tensor([0.4302, 0.4194, 0.4211, 0.4201, 0.4373], grad_fn=<SqueezeBackward3>) tensor([-0.9683, -5.4463, -7.0306, -3.7832, -1.1615], grad_fn=<SubBackward0>)\n",
      "tensor(-2.1280, grad_fn=<NegBackward0>)\n",
      "tensor([0.4303, 0.4194, 0.4211, 0.4202, 0.4374], grad_fn=<SqueezeBackward3>) tensor([-0.9678, -5.4453, -7.0304, -3.7825, -1.1604], grad_fn=<SubBackward0>)\n",
      "tensor(-2.1284, grad_fn=<NegBackward0>)\n",
      "tensor([0.4303, 0.4195, 0.4212, 0.4203, 0.4375], grad_fn=<SqueezeBackward3>) tensor([-0.9672, -5.4443, -7.0302, -3.7818, -1.1593], grad_fn=<SubBackward0>)\n",
      "tensor(-2.1288, grad_fn=<NegBackward0>)\n",
      "tensor([0.4304, 0.4196, 0.4212, 0.4203, 0.4376], grad_fn=<SqueezeBackward3>) tensor([-0.9667, -5.4433, -7.0299, -3.7811, -1.1582], grad_fn=<SubBackward0>)\n",
      "tensor(-2.1291, grad_fn=<NegBackward0>)\n",
      "tensor([0.4305, 0.4196, 0.4213, 0.4204, 0.4377], grad_fn=<SqueezeBackward3>) tensor([-0.9661, -5.4422, -7.0297, -3.7804, -1.1571], grad_fn=<SubBackward0>)\n",
      "tensor(-2.1295, grad_fn=<NegBackward0>)\n",
      "tensor([0.4306, 0.4197, 0.4214, 0.4204, 0.4378], grad_fn=<SqueezeBackward3>) tensor([-0.9656, -5.4412, -7.0295, -3.7797, -1.1561], grad_fn=<SubBackward0>)\n",
      "tensor(-2.1299, grad_fn=<NegBackward0>)\n",
      "tensor([0.4307, 0.4197, 0.4214, 0.4205, 0.4379], grad_fn=<SqueezeBackward3>) tensor([-0.9650, -5.4402, -7.0292, -3.7790, -1.1550], grad_fn=<SubBackward0>)\n",
      "tensor(-2.1302, grad_fn=<NegBackward0>)\n",
      "tensor([0.4308, 0.4198, 0.4215, 0.4206, 0.4380], grad_fn=<SqueezeBackward3>) tensor([-0.9645, -5.4391, -7.0290, -3.7783, -1.1539], grad_fn=<SubBackward0>)\n",
      "tensor(-2.1306, grad_fn=<NegBackward0>)\n",
      "tensor([0.4308, 0.4199, 0.4215, 0.4206, 0.4381], grad_fn=<SqueezeBackward3>) tensor([-0.9639, -5.4381, -7.0287, -3.7776, -1.1528], grad_fn=<SubBackward0>)\n",
      "tensor(-2.1309, grad_fn=<NegBackward0>)\n",
      "tensor([0.4309, 0.4199, 0.4216, 0.4207, 0.4382], grad_fn=<SqueezeBackward3>) tensor([-0.9633, -5.4371, -7.0284, -3.7769, -1.1517], grad_fn=<SubBackward0>)\n",
      "tensor(-2.1313, grad_fn=<NegBackward0>)\n",
      "tensor([0.4310, 0.4200, 0.4217, 0.4208, 0.4383], grad_fn=<SqueezeBackward3>) tensor([-0.9628, -5.4360, -7.0282, -3.7762, -1.1506], grad_fn=<SubBackward0>)\n",
      "tensor(-2.1317, grad_fn=<NegBackward0>)\n",
      "tensor([0.4311, 0.4201, 0.4217, 0.4208, 0.4383], grad_fn=<SqueezeBackward3>) tensor([-0.9622, -5.4350, -7.0279, -3.7755, -1.1496], grad_fn=<SubBackward0>)\n",
      "tensor(-2.1320, grad_fn=<NegBackward0>)\n",
      "tensor([0.4312, 0.4201, 0.4218, 0.4209, 0.4384], grad_fn=<SqueezeBackward3>) tensor([-0.9616, -5.4340, -7.0276, -3.7748, -1.1485], grad_fn=<SubBackward0>)\n",
      "tensor(-2.1324, grad_fn=<NegBackward0>)\n",
      "tensor([0.4313, 0.4202, 0.4218, 0.4210, 0.4385], grad_fn=<SqueezeBackward3>) tensor([-0.9610, -5.4329, -7.0274, -3.7740, -1.1474], grad_fn=<SubBackward0>)\n",
      "tensor(-2.1328, grad_fn=<NegBackward0>)\n",
      "tensor([0.4313, 0.4202, 0.4219, 0.4210, 0.4386], grad_fn=<SqueezeBackward3>) tensor([-0.9604, -5.4319, -7.0271, -3.7733, -1.1463], grad_fn=<SubBackward0>)\n",
      "tensor(-2.1331, grad_fn=<NegBackward0>)\n",
      "tensor([0.4314, 0.4203, 0.4220, 0.4211, 0.4387], grad_fn=<SqueezeBackward3>) tensor([-0.9598, -5.4308, -7.0268, -3.7726, -1.1452], grad_fn=<SubBackward0>)\n",
      "tensor(-2.1335, grad_fn=<NegBackward0>)\n",
      "tensor([0.4315, 0.4204, 0.4220, 0.4212, 0.4388], grad_fn=<SqueezeBackward3>) tensor([-0.9591, -5.4298, -7.0265, -3.7719, -1.1442], grad_fn=<SubBackward0>)\n",
      "tensor(-2.1339, grad_fn=<NegBackward0>)\n",
      "tensor([0.4316, 0.4204, 0.4221, 0.4212, 0.4389], grad_fn=<SqueezeBackward3>) tensor([-0.9585, -5.4287, -7.0263, -3.7712, -1.1431], grad_fn=<SubBackward0>)\n",
      "tensor(-2.1342, grad_fn=<NegBackward0>)\n",
      "tensor([0.4317, 0.4205, 0.4221, 0.4213, 0.4390], grad_fn=<SqueezeBackward3>) tensor([-0.9579, -5.4277, -7.0260, -3.7705, -1.1420], grad_fn=<SubBackward0>)\n",
      "tensor(-2.1346, grad_fn=<NegBackward0>)\n",
      "tensor([0.4318, 0.4206, 0.4222, 0.4213, 0.4391], grad_fn=<SqueezeBackward3>) tensor([-0.9573, -5.4266, -7.0257, -3.7698, -1.1409], grad_fn=<SubBackward0>)\n",
      "tensor(-2.1350, grad_fn=<NegBackward0>)\n",
      "tensor([0.4318, 0.4206, 0.4223, 0.4214, 0.4392], grad_fn=<SqueezeBackward3>) tensor([-0.9566, -5.4256, -7.0254, -3.7690, -1.1399], grad_fn=<SubBackward0>)\n",
      "tensor(-2.1353, grad_fn=<NegBackward0>)\n",
      "tensor([0.4319, 0.4207, 0.4223, 0.4215, 0.4393], grad_fn=<SqueezeBackward3>) tensor([-0.9560, -5.4245, -7.0251, -3.7683, -1.1388], grad_fn=<SubBackward0>)\n",
      "tensor(-2.1357, grad_fn=<NegBackward0>)\n",
      "tensor([0.4320, 0.4207, 0.4224, 0.4215, 0.4394], grad_fn=<SqueezeBackward3>) tensor([-0.9553, -5.4235, -7.0248, -3.7676, -1.1377], grad_fn=<SubBackward0>)\n",
      "tensor(-2.1360, grad_fn=<NegBackward0>)\n",
      "tensor([0.4321, 0.4208, 0.4224, 0.4216, 0.4395], grad_fn=<SqueezeBackward3>) tensor([-0.9547, -5.4224, -7.0245, -3.7669, -1.1366], grad_fn=<SubBackward0>)\n",
      "tensor(-2.1364, grad_fn=<NegBackward0>)\n",
      "tensor([0.4322, 0.4209, 0.4225, 0.4217, 0.4396], grad_fn=<SqueezeBackward3>) tensor([-0.9540, -5.4214, -7.0242, -3.7661, -1.1356], grad_fn=<SubBackward0>)\n",
      "tensor(-2.1368, grad_fn=<NegBackward0>)\n",
      "tensor([0.4323, 0.4209, 0.4226, 0.4217, 0.4397], grad_fn=<SqueezeBackward3>) tensor([-0.9533, -5.4203, -7.0238, -3.7654, -1.1345], grad_fn=<SubBackward0>)\n",
      "tensor(-2.1371, grad_fn=<NegBackward0>)\n",
      "tensor([0.4323, 0.4210, 0.4226, 0.4218, 0.4398], grad_fn=<SqueezeBackward3>) tensor([-0.9526, -5.4193, -7.0235, -3.7647, -1.1334], grad_fn=<SubBackward0>)\n",
      "tensor(-2.1375, grad_fn=<NegBackward0>)\n",
      "tensor([0.4324, 0.4211, 0.4227, 0.4219, 0.4399], grad_fn=<SqueezeBackward3>) tensor([-0.9520, -5.4182, -7.0232, -3.7639, -1.1324], grad_fn=<SubBackward0>)\n",
      "tensor(-2.1379, grad_fn=<NegBackward0>)\n",
      "tensor([0.4325, 0.4211, 0.4227, 0.4219, 0.4400], grad_fn=<SqueezeBackward3>) tensor([-0.9513, -5.4171, -7.0229, -3.7632, -1.1313], grad_fn=<SubBackward0>)\n",
      "tensor(-2.1382, grad_fn=<NegBackward0>)\n",
      "tensor([0.4326, 0.4212, 0.4228, 0.4220, 0.4401], grad_fn=<SqueezeBackward3>) tensor([-0.9506, -5.4161, -7.0225, -3.7625, -1.1302], grad_fn=<SubBackward0>)\n",
      "tensor(-2.1386, grad_fn=<NegBackward0>)\n",
      "tensor([0.4327, 0.4212, 0.4229, 0.4221, 0.4402], grad_fn=<SqueezeBackward3>) tensor([-0.9499, -5.4150, -7.0222, -3.7617, -1.1292], grad_fn=<SubBackward0>)\n",
      "tensor(-2.1390, grad_fn=<NegBackward0>)\n",
      "tensor([0.4328, 0.4213, 0.4229, 0.4221, 0.4403], grad_fn=<SqueezeBackward3>) tensor([-0.9492, -5.4139, -7.0219, -3.7610, -1.1281], grad_fn=<SubBackward0>)\n",
      "tensor(-2.1393, grad_fn=<NegBackward0>)\n",
      "tensor([0.4328, 0.4214, 0.4230, 0.4222, 0.4403], grad_fn=<SqueezeBackward3>) tensor([-0.9485, -5.4129, -7.0215, -3.7603, -1.1270], grad_fn=<SubBackward0>)\n",
      "tensor(-2.1397, grad_fn=<NegBackward0>)\n",
      "tensor([0.4329, 0.4214, 0.4230, 0.4222, 0.4404], grad_fn=<SqueezeBackward3>) tensor([-0.9478, -5.4118, -7.0212, -3.7595, -1.1260], grad_fn=<SubBackward0>)\n",
      "tensor(-2.1401, grad_fn=<NegBackward0>)\n",
      "tensor([0.4330, 0.4215, 0.4231, 0.4223, 0.4405], grad_fn=<SqueezeBackward3>) tensor([-0.9470, -5.4107, -7.0208, -3.7588, -1.1249], grad_fn=<SubBackward0>)\n",
      "tensor(-2.1404, grad_fn=<NegBackward0>)\n",
      "tensor([0.4331, 0.4215, 0.4232, 0.4224, 0.4406], grad_fn=<SqueezeBackward3>) tensor([-0.9463, -5.4097, -7.0205, -3.7580, -1.1238], grad_fn=<SubBackward0>)\n",
      "tensor(-2.1408, grad_fn=<NegBackward0>)\n",
      "tensor([0.4332, 0.4216, 0.4232, 0.4224, 0.4407], grad_fn=<SqueezeBackward3>) tensor([-0.9456, -5.4086, -7.0201, -3.7573, -1.1228], grad_fn=<SubBackward0>)\n",
      "tensor(-2.1412, grad_fn=<NegBackward0>)\n",
      "tensor([0.4333, 0.4217, 0.4233, 0.4225, 0.4408], grad_fn=<SqueezeBackward3>) tensor([-0.9449, -5.4075, -7.0198, -3.7566, -1.1217], grad_fn=<SubBackward0>)\n",
      "tensor(-2.1415, grad_fn=<NegBackward0>)\n",
      "tensor([0.4333, 0.4217, 0.4233, 0.4226, 0.4409], grad_fn=<SqueezeBackward3>) tensor([-0.9441, -5.4064, -7.0194, -3.7558, -1.1207], grad_fn=<SubBackward0>)\n",
      "tensor(-2.1419, grad_fn=<NegBackward0>)\n",
      "tensor([0.4334, 0.4218, 0.4234, 0.4226, 0.4410], grad_fn=<SqueezeBackward3>) tensor([-0.9434, -5.4053, -7.0191, -3.7551, -1.1196], grad_fn=<SubBackward0>)\n",
      "tensor(-2.1423, grad_fn=<NegBackward0>)\n",
      "tensor([0.4335, 0.4219, 0.4235, 0.4227, 0.4411], grad_fn=<SqueezeBackward3>) tensor([-0.9426, -5.4043, -7.0187, -3.7543, -1.1185], grad_fn=<SubBackward0>)\n",
      "tensor(-2.1426, grad_fn=<NegBackward0>)\n",
      "tensor([0.4336, 0.4219, 0.4235, 0.4228, 0.4412], grad_fn=<SqueezeBackward3>) tensor([-0.9419, -5.4032, -7.0183, -3.7535, -1.1175], grad_fn=<SubBackward0>)\n",
      "tensor(-2.1430, grad_fn=<NegBackward0>)\n",
      "tensor([0.4337, 0.4220, 0.4236, 0.4228, 0.4413], grad_fn=<SqueezeBackward3>) tensor([-0.9411, -5.4021, -7.0179, -3.7528, -1.1164], grad_fn=<SubBackward0>)\n",
      "tensor(-2.1434, grad_fn=<NegBackward0>)\n",
      "tensor([0.4338, 0.4220, 0.4236, 0.4229, 0.4414], grad_fn=<SqueezeBackward3>) tensor([-0.9404, -5.4010, -7.0176, -3.7520, -1.1154], grad_fn=<SubBackward0>)\n",
      "tensor(-2.1437, grad_fn=<NegBackward0>)\n",
      "tensor([0.4338, 0.4221, 0.4237, 0.4230, 0.4415], grad_fn=<SqueezeBackward3>) tensor([-0.9396, -5.3999, -7.0172, -3.7513, -1.1143], grad_fn=<SubBackward0>)\n",
      "tensor(-2.1441, grad_fn=<NegBackward0>)\n",
      "tensor([0.4339, 0.4222, 0.4238, 0.4230, 0.4416], grad_fn=<SqueezeBackward3>) tensor([-0.9388, -5.3988, -7.0168, -3.7505, -1.1133], grad_fn=<SubBackward0>)\n",
      "tensor(-2.1445, grad_fn=<NegBackward0>)\n",
      "tensor([0.4340, 0.4222, 0.4238, 0.4231, 0.4417], grad_fn=<SqueezeBackward3>) tensor([-0.9381, -5.3977, -7.0164, -3.7498, -1.1122], grad_fn=<SubBackward0>)\n",
      "tensor(-2.1448, grad_fn=<NegBackward0>)\n",
      "tensor([0.4341, 0.4223, 0.4239, 0.4231, 0.4418], grad_fn=<SqueezeBackward3>) tensor([-0.9373, -5.3966, -7.0160, -3.7490, -1.1112], grad_fn=<SubBackward0>)\n",
      "tensor(-2.1452, grad_fn=<NegBackward0>)\n",
      "tensor([0.4342, 0.4224, 0.4239, 0.4232, 0.4419], grad_fn=<SqueezeBackward3>) tensor([-0.9365, -5.3956, -7.0156, -3.7482, -1.1101], grad_fn=<SubBackward0>)\n",
      "tensor(-2.1456, grad_fn=<NegBackward0>)\n",
      "tensor([0.4343, 0.4224, 0.4240, 0.4233, 0.4420], grad_fn=<SqueezeBackward3>) tensor([-0.9357, -5.3945, -7.0152, -3.7475, -1.1091], grad_fn=<SubBackward0>)\n",
      "tensor(-2.1460, grad_fn=<NegBackward0>)\n",
      "tensor([0.4344, 0.4225, 0.4241, 0.4233, 0.4421], grad_fn=<SqueezeBackward3>) tensor([-0.9349, -5.3934, -7.0148, -3.7467, -1.1080], grad_fn=<SubBackward0>)\n",
      "tensor(-2.1463, grad_fn=<NegBackward0>)\n",
      "tensor([0.4344, 0.4225, 0.4241, 0.4234, 0.4422], grad_fn=<SqueezeBackward3>) tensor([-0.9341, -5.3923, -7.0144, -3.7459, -1.1070], grad_fn=<SubBackward0>)\n",
      "tensor(-2.1467, grad_fn=<NegBackward0>)\n",
      "tensor([0.4345, 0.4226, 0.4242, 0.4235, 0.4423], grad_fn=<SqueezeBackward3>) tensor([-0.9333, -5.3912, -7.0139, -3.7452, -1.1059], grad_fn=<SubBackward0>)\n",
      "tensor(-2.1471, grad_fn=<NegBackward0>)\n",
      "tensor([0.4346, 0.4227, 0.4242, 0.4235, 0.4424], grad_fn=<SqueezeBackward3>) tensor([-0.9325, -5.3900, -7.0135, -3.7444, -1.1049], grad_fn=<SubBackward0>)\n",
      "tensor(-2.1474, grad_fn=<NegBackward0>)\n",
      "tensor([0.4347, 0.4227, 0.4243, 0.4236, 0.4425], grad_fn=<SqueezeBackward3>) tensor([-0.9317, -5.3889, -7.0131, -3.7436, -1.1038], grad_fn=<SubBackward0>)\n",
      "tensor(-2.1478, grad_fn=<NegBackward0>)\n",
      "tensor([0.4348, 0.4228, 0.4244, 0.4237, 0.4426], grad_fn=<SqueezeBackward3>) tensor([-0.9309, -5.3878, -7.0127, -3.7428, -1.1028], grad_fn=<SubBackward0>)\n",
      "tensor(-2.1482, grad_fn=<NegBackward0>)\n",
      "tensor([0.4349, 0.4229, 0.4244, 0.4237, 0.4427], grad_fn=<SqueezeBackward3>) tensor([-0.9301, -5.3867, -7.0122, -3.7420, -1.1017], grad_fn=<SubBackward0>)\n",
      "tensor(-2.1485, grad_fn=<NegBackward0>)\n",
      "tensor([0.4349, 0.4229, 0.4245, 0.4238, 0.4428], grad_fn=<SqueezeBackward3>) tensor([-0.9293, -5.3856, -7.0118, -3.7413, -1.1007], grad_fn=<SubBackward0>)\n",
      "tensor(-2.1489, grad_fn=<NegBackward0>)\n",
      "tensor([0.4350, 0.4230, 0.4245, 0.4239, 0.4429], grad_fn=<SqueezeBackward3>) tensor([-0.9285, -5.3845, -7.0113, -3.7405, -1.0996], grad_fn=<SubBackward0>)\n",
      "tensor(-2.1493, grad_fn=<NegBackward0>)\n",
      "tensor([0.4351, 0.4230, 0.4246, 0.4239, 0.4430], grad_fn=<SqueezeBackward3>) tensor([-0.9277, -5.3834, -7.0109, -3.7397, -1.0986], grad_fn=<SubBackward0>)\n",
      "tensor(-2.1496, grad_fn=<NegBackward0>)\n",
      "tensor([0.4352, 0.4231, 0.4247, 0.4240, 0.4431], grad_fn=<SqueezeBackward3>) tensor([-0.9268, -5.3823, -7.0105, -3.7389, -1.0976], grad_fn=<SubBackward0>)\n",
      "tensor(-2.1500, grad_fn=<NegBackward0>)\n",
      "tensor([0.4353, 0.4232, 0.4247, 0.4240, 0.4432], grad_fn=<SqueezeBackward3>) tensor([-0.9260, -5.3812, -7.0100, -3.7381, -1.0965], grad_fn=<SubBackward0>)\n",
      "tensor(-2.1504, grad_fn=<NegBackward0>)\n",
      "tensor([0.4354, 0.4232, 0.4248, 0.4241, 0.4433], grad_fn=<SqueezeBackward3>) tensor([-0.9252, -5.3800, -7.0095, -3.7373, -1.0955], grad_fn=<SubBackward0>)\n",
      "tensor(-2.1508, grad_fn=<NegBackward0>)\n",
      "tensor([0.4355, 0.4233, 0.4248, 0.4242, 0.4434], grad_fn=<SqueezeBackward3>) tensor([-0.9244, -5.3789, -7.0091, -3.7365, -1.0944], grad_fn=<SubBackward0>)\n",
      "tensor(-2.1511, grad_fn=<NegBackward0>)\n",
      "tensor([0.4355, 0.4233, 0.4249, 0.4242, 0.4435], grad_fn=<SqueezeBackward3>) tensor([-0.9235, -5.3778, -7.0086, -3.7358, -1.0934], grad_fn=<SubBackward0>)\n",
      "tensor(-2.1515, grad_fn=<NegBackward0>)\n",
      "tensor([0.4356, 0.4234, 0.4250, 0.4243, 0.4436], grad_fn=<SqueezeBackward3>) tensor([-0.9227, -5.3767, -7.0081, -3.7350, -1.0924], grad_fn=<SubBackward0>)\n",
      "tensor(-2.1519, grad_fn=<NegBackward0>)\n",
      "tensor([0.4357, 0.4235, 0.4250, 0.4244, 0.4436], grad_fn=<SqueezeBackward3>) tensor([-0.9218, -5.3755, -7.0077, -3.7342, -1.0913], grad_fn=<SubBackward0>)\n",
      "tensor(-2.1522, grad_fn=<NegBackward0>)\n",
      "tensor([0.4358, 0.4235, 0.4251, 0.4244, 0.4437], grad_fn=<SqueezeBackward3>) tensor([-0.9210, -5.3744, -7.0072, -3.7334, -1.0903], grad_fn=<SubBackward0>)\n",
      "tensor(-2.1526, grad_fn=<NegBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[0.2816, 0.4512],\n",
       "         [0.7196, 0.8424]], requires_grad=True),\n",
       " tensor([ 0.0297, -0.0313], requires_grad=True))"
      ]
     },
     "execution_count": 905,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l1norm_phi(Xs, W, u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 853,
   "id": "d93e8a81",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alex\\AppData\\Local\\Temp\\ipykernel_39092\\828025484.py:27: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  reward = u @ softmax(phi @ X_hat + b)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([0.7010, 0.8703]), tensor([0.7142, 0.8769], requires_grad=True))"
      ]
     },
     "execution_count": 853,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.rand(d)\n",
    "phi = torch.rand((m, d))\n",
    "b = torch.zeros(m)\n",
    "X, softmax_gragent(X, phi, b, u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 821,
   "id": "57ee4831",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(X, phi, b):\n",
    "    m, d = phi.shape\n",
    "    one_m = torch.ones(m, dtype=torch.float64)\n",
    "    action = phi @ X + b\n",
    "    return action / (one_m @ action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 822,
   "id": "69dfc366",
   "metadata": {},
   "outputs": [],
   "source": [
    "# classify(X, phi, b), classify(X_hat, phi, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 834,
   "id": "19bc9969",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.5595, 0.0952],\n",
       "         [0.1264, 0.7859]]),\n",
       " tensor([0., 0.]))"
      ]
     },
     "execution_count": 834,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_phi, true_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ddaa04",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_phi = torch.rand((m, d))\n",
    "true_b = torch.zeros(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 833,
   "id": "11310d46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x247f2b82520>"
      ]
     },
     "execution_count": 833,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAABCWUlEQVR4nO2dd5hcZfXHP+dO3b5JNr0nhBJAWmiCFAWpAtJRIigICogIiAiIFFEQQZQfiKCI9F4CBEMnlAAJBAIJJQkhvW2yyZbpc8/vjztJNpsts7t3yt19P8+TJzsz75z33Dv3fu/7nrccUVUMBoPB4H2sQjtgMBgMBncwgm4wGAw9BCPoBoPB0EMwgm4wGAw9BCPoBoPB0EPwF6rimpoaHTVqVKGqNxgMBk/ywQcf1Kpq/9Y+K5igjxo1ihkzZhSqeoPBYPAkIrKwrc9MyMVgMBh6CEbQDQaDoYdgBN1gMBh6CEbQDQaDoYfQKwRdNYna9RTrvjVqN6KpeajdVGhXuoWmV6CJ6Wh6jfu27UbUrnPdbqFRVTS9CrUjBfYjgaYWoxrNcT0pNL0UtRtbvJ9GNdVJW+r43Yn7Wu2GzL0W2WQjvRK165uVWZu5jpd2yp9ioMNZLiJyN3AksEpVd2jlcwH+BhwORIDTVfVDtx1tjtr1aOR+iE8F3yCk9HQkuLPzmSYh8R5oExrYDZrugshDQAqkL1pyLNjLIDEdtAH82yEVv974/bbrrEMbrofYFOeN0CFI5aWI1QcAO7kAUrMRbUAJgN2IWBUQPhg0ikYnQ2IakITQgUjJ8SgW1F8DsWdB/KBptHQiUnERIt171qoqpD4Bux4COzm+ZLAjT0PDn0DXAX4IHQpVN2BZXZv0pBpH110M8ddBgqBxtOQYpPJqRHyblSP+KqRXQWBn1L8taCOklkPqfdAkEtjBubEj/4H0aghOgNQ8SH4IpFF8IGGQUgjuByXHI8Fdun2+uoradaBxsAYiImjiY7TxNkh+Aij4t0HKz0ZC39z8e6l5aP21kJgB2ICFhr+LVP4Bsco2lUsvQ6MvQno++IZB6CCswNhM3Y2QXgi+wYjVd9N3knMgOQusgRD6Fhp7AeqvB10LUgkVv8IqPdkpq4o23QVNt4MqYKMlR4PVHxLvgzUIys7ECm63yb5G0ab7nOuWIFJ6CpQcu9lvoPY6tOEmiP0PsKDkSPBtBY03gyaANBo+FCougvo/Qfxlp27fSJAKsPpC6GAITkD8o3Bkhk0+Rx6ExltB68Dqi5ZfjFV6XBu/UQMafR6iT0BqjuMPSZQQkHB+Jyw0uBf4BkP0GZAQaMJ5r+oWROIgZYiEOneBtPRFFbQJJIyI+5MMpaOnm4jsBzQC97Yh6IcDv8AR9D2Bv6nqnh1VPGHCBO3KtEW116G1R4O9FogDAoSg8iokMA5dewaQedJrNPN5R0/+MNL33jZF3Y5OhvWX4Pz4G/CDbyiU/QrqW37WEsG5aDbVh1XmiC3JFmWDUHEhUnKiI5CkIPgtxNdv0zlQdW7Y9ELwbwP+rRxh0IgjgHYdWvcTRxARp47AbkDUcSP1cSs+liMDXt5MGLLFXn8VRB9rcSxBKD8fq/wsx+fUV+iaHwDxzA1tZ/650WsSCOwBof2RwDgI7rvxQaKJ6Wj99ZD6HKx+UHY2UvoDSLyDNt4O6SXOA6/ifMS/lfMdjaPRZyH2svPQs8YCjZCaDdYgpPxs8G+DrrsQkjMBC6waKDkBmm5jy980BBUXYZWd7tiPT0PrznLOxWYEILQPVp87nfPa8DdougNItzjcIRD6FsSeBgk45zN8MFT+Adb/GuJvZcr5QMXxvSX+nZHK36DJ+dBwHdBBy7zkeKTyOiCFrjkRUvOB2IYPIXwQVvVN2NHnoOHPYK9oYcDHlr93MNMAiNH2Pep3HpbVtyDBnZzzUn8TRO5sYUsg8G3wlUJgR6TkOMSqQBMznXtBY2xxHrPCBwQyvguUHA1lZ0Lj/0H8Tec+Lj0NKZ3YYaPCbnoUGv/iNCQJQOkPM423zgm7iHygqhNa/Syb7oqIjAKea0PQ/wm8rqoPZV5/ARygqsvbs9kVQVe7Hl17JqQ+auXTksxTdV2nbG4kuCdW3/u2eNtuuhsa/kLrF1wJHd4IXXMG52IVnNaEDb6RkF4GhJ3XRDKt+qRTVoJOeU3gXIRd8Mu/I1bNE0Cm29n4T0ccfEOg5CRIfQjRyU4LufRkpPRUQNCV32BLEcPxp+QHSPnPnZsqNRd3BLw9QiAlUHUdWANg7UQ2CQ8457OUzUXOclpMfR8B8aFrTsrcdG0RBil3WodZi0QIal6G2DPQ+HfabgBYUH27cy3X/byF7+1hgW8spBd34jthnGssm2tFoPw3iH8wuu7SVr4ThNBxEH8oy7o7SwgZMBXsBrT2oA7KljjXQL/HYe2JYNe66MeGezONcx86vlHyPayqPwIbIggPOA0yayCUngaRu5zeaYtjouQ4rKqrOuVBrgX9OeB6VX0r8/oV4DequoVai8hZwFkAI0aM2G3hwjbnx2+BahytPQrSX5MbUbDAN9x5kof2Qcp/CVYfdOVutC5WPZTyiyG4O6w9lfaPO+yEAKQCUjPbKefPiF9TB/ZyQcueUQdlA7tD8lOcyKHblIFVDvY6tmyZewULR9CyfWC4TPh7kFoBqelZFLbAPwFSufo9WyPkhIrsSKbObK73EDLg3c3CbB3RnqDndaWoqt4J3AlOC71TX449n+nG5aqFZzshDIDoM2jsVaj6C71KzAEabyK7cxyD9LwsyqWcOHmHYa9c0JlrRSH5fs48gRjYSdoPzRU7NgUTc8iMX2V7/mxnXCavxMFuNzDRCuL0IDoh6O3hhqAvBYY3ez0s856raPzdTEw8H6SdeHT00TzVV0zk4oFZCDEvNtJ0LYZr2ISXH4ZtkQLfINesuTE1YBLwI3HYC1jfUfy8S6SXuW6yfRKZkXeDwdC7sHDGx/JBn27PnGlONtMWHwIOAGpEZAnwe5xhX1T1DmAyzgyXeTiBox+75l1zUnNyYrZ97I6LGAwGj+HD6Ym2dX8ruZns0AouT7ftUNBV9ZQOPlfgXNc8ar2OzKCaIbd0ZhDRYPAqHYW+8ngPaH3HZTqBJ1aKigj4ty20G70AI+YGQ15ptr7EDTwh6ABSeSWb5s0aDAaD1wlB6VmuWvSOoAd3Q/o9BqHDcITdYOgqPkzDoBkyFqyRhfaiF5KG0P6uWvSMoANIYBtnObNnF2YYioM0JrzUDJ0PdvaL/AxukYLo/a5a9JSga/JziL2EuRkNBkOPIPqKq+Y8JejOznRGzHsn3rpUDYassBe7as5bd4mvH15z2eAS1sBCe2Aw5AB3txbxlDpq9CXyNuHfUFyEDsa7A5lu+Z2v1YuG/OHuNe0ZQbejz0P8uUK7YSgU0XspnnBbJ28b6QdlF0DFVXRPlL3SmAkB7s6v7rH4xrpqzjOCTuPthfbAYMjQyS0htBaaboH4NCcBSY+adutjSxkJAO6nIeyRhL/rqjnvCLq9vtAeGAzdIzEFEsvpWVsyV7DlA66VDEmGVhCk5GhXLXpH0P3jCu2BweAC8+hZ2+iuK7QDXcRHwXtKpach/tGumvSOoAd2LLQHBoOhRxCCkokU7sEahPIrsSovc91yXjMWdQfxD89k6TarRA0GQ1exoORHEL2rQPUHod8TWIFtcmLdMy10DeyEEXODwdA97AKKOUAC1v2CbHI5dwXPCDqRR3DiXgaDweBh0ssgvSAnpr0j6MmP6FmDSQZDTyIEMqbQTniEBNr0WE4se0fQ/VvhJXcNbmB+b++QBs1Nq7NHEv0vGnV/oaRn7hgpOwMIFtoNQz4JHU7Bp5YZsiRF91byhqDkJyAVbjlU5KTQxttct+odQQ9sDcF9C+2GIV+EjkWqfg+BvQrtiSEvJCH8bQgdW2hH8oe90nWTnpm2CEDijUJ7YMCi00vfu0L8KXTVM/mpq11M4uz8YEPd6eDrRZmTAtu7btIzgq52PT1rybRXyZfAKsUxCG7EPH+kID2/0E7kiSBS8WvXrXom5KJ2pNAuGAy9G2sE+MyKbVeouAwJfMN1s54RdKIPFdoDg6EX44fSMyH9aaEd6QH4Ed+AnFj2jqBHcjNv02AwZEnjlZgQlBuk0NgLObHsCUFXTTp7ShsMxYyU0XNXM6cK7UDPIvYsduxV1816QtCdm8Qz47eGXokPtIniGMg1eIKGW1w36QlBF7EgfFih3TC0RfBg6Ps8Tqaa3ooRcgev5n0tAOnFrpv0hKADUH5hoT0wtIUIVnAcVP4RJ5+kuakNhg6xyl036Z04RuP/FdoDQ1vE38FedQBoA2aL496OGTTNGnW/V+cdQU/NKbQHhjZpBNvkkTQYOoWuQ+06xOrjmsmsQi4icqiIfCEi80Tk0lY+HyEir4nITBGZJSKHu+bhBgJ7uG7SYDAYCkcaJ0TpHh0Kuoj4gNuAw4DxwCkiMr5FsSuAR1V1F+Bk4HZXvQQoOcZ1kwaDoUgJ7IWXAghdI4BYpa5azKaFvgcwT1W/UtUE8DBwdIsyClRm/q4ClrnnooMkZ9Lzf2CDoTmCl+YtuEcYwgexSVJ6KOL+atFsFHIo0Hx+zRJgzxZlrgJeFJFfAGXAQa0ZEpGzgLMARowY0SlHFR9mcYOhd6H0zkHGGDT8iR4/FbTsNNdNuvX4PwW4R1WHAYcD94nIFrZV9U5VnaCqE/r379+5GvxDXXHUYDB4gR4u5tZQpGyi+2azKLMUGN7s9bDMe805A3gUQFWn4aSZqXHDwY1owlVzBoPBUBACeyP9p9BKm7fbZGNxOjBOREaLSBBn0HNSizKLgO8AiMh2OIK+2k1HSbmf3cNgMBjySyn4h4O9NifWOxR0VU0B5wFTgM9wZrPMFpFrROSoTLGLgJ+KyMfAQ8Dpqupu8C/6oKvmDIb8EsasoC0UxXTeIxB9FK09Ek0tct16VtNGVHUyMLnFe1c2+3sOsI+7rrUgvTCn5g2G3BIDGQX6daEd6YUU4cCyNqCNtyDVN7tq1kNzoorwRzEYOoMRc8NGFBLTXLfqHUEP5rYDYDB4k2IKJxg6h/u7k3pH0MvPKbQHBkMR4qWea67lpioPdbiIvRpNurtHlXeOPvFeoT0wuI67y54NxY6dY/vr81CHm6TRpv+4atE7gh6bWmgPDK4TxYQMDL2a1FeumvPO5ij28kJ7YHAdL4ULDIYcEJzgqjnvtNCtgYX2wGBoBYHKP9Nzk0MbcocPKTvLVYueEXQpPw1ncYbBUEwoNNxMzw0dmQdVbghC3/sQXz9XrXpG0AkdAuFDC+2FwbAluoKeuxNoD98kq1CU/gTL5XALeEnQU19A7H+F9sJgMBi6T/SBnJj1jKBr461ArNBuGAwGQ/fR3OTg9Yygk/io0B4YDAaDS+RmzMU7gp6jJ5rBYDDkHcv99HPgEUHX1GJ67qCTwWDodZRfkBOznhB0M9Lekp46Rc5LdDSFNgAMyYcjBi9iuZvQbaPZnFh1G99IEDMHfRNmhWXhiQHBNj7bsEfNsjz5YvAc9dfkxKwnBF1EoMzstmgoNtrKcxsBkvl0xOA17EWoun+NeELQAQjtW2gPihgfJgxjMHgLVffvWc8IulhVhXahiEnj7LPWVgjAYDAUFz6EetetekbQkUpy525PiM8naTsEYDAYigopyWiau3hG0J2VornavN6sQDUUGs/cioZuUwJlZyPi/u7l3rmKYk/noRLBxKINHSO4f+uEwBrkgh0B/06Y67hY8UPFr1zfNncD3hF0zcfCIgVrbB7q6SoW+HekcD+beeA5KO73FqNgr3DBjkL6KxB3t2U1uIWNhA5wZu7lAO8IeviQ/NRjz8tPPV3CD5W/o3B5ExUvXTK9Fm0EdX/AzeAGNlp3Fqq5uYe9c3eW/qjQHnRAHlquEoa1p+S+nnYxq3Ydijnxg2IGyIuY9CKIvZAT054RdLFXA+WFdqMdcr16M5BpdRlBbZtAnuoJQ3D/PNVl6HnYaOSxnFj2jKDjG0bv2qBrw8BbFfh2w0v5vAtHHlZn+naAPndA8t3c12XosXz69mfM/fAr1+16RtDFPxJ8w7MtnVNf8kLF76DvQ2BVQPpTIFpojwwAdh2kG+gR15ghbyTiwtTnKrnj94P5fGaY5++t4JKDriEWibtaj2eafZpe7sSesiudU1/yQtM/nf/tlYX1w7A5uhTqL8BDbSFDERAMKbvs08SffjaSZ++pIZ0SQqUppk2awYEn7+NaPd65KmOT6RFCnS32yh4g5mEov4j8bkmQj8HKNGbzrc7Qkcz0jt5OqNSmrMomlbRQFWJNcZbOW+5qHVkJuogcKiJfiMg8Ebm0jTInisgcEZktIg+66iWgdoTeFUP3ONIHJAhN/wLfGCBUaI8MeScElTeAlHZctBeQTAhN9Zs3OObPXOBqHR2GXETEB9wGHAwsAaaLyCRVndOszDjgt8A+qlonIq7nV5LwAWjTXZhl+sWOBdbATO8iM9c2vT6P9ZtZQMVDAqLP0XHP2qs9bwtVm9bWCKmy2fvRJovHbh+And688JxpX7rqUTYx9D2Aear6FYCIPAwcDcxpVuanwG2qWgegqqtc9RKQwI5oyTEQewbUDBAWLzbY7nYjDV5FIfkOPSGkUrfaz7QplaTTwp4H1TP50UOZ/O+veeSTTwCwbXjzuSqmPNwXFA46sY6d9m6gun+aSIOPR27tz2P/2LKdW1btbu8lG0EfCixu9noJsGeLMlsDiMjbOEHMq1T1fy0NichZwFkAI0aM6LSzUnk1hA9D150D2tTp7xsMhScEuDuzobjxfo/pjUmV/OWXIxHL6UncedUQ9jtqJuvX9uOt5yvZ94h6/vyLEUybUkks4oRUPnm3nERc8AeUVLL1LTNCpSG+f/7hrvrq1iwXPzAOOAAYBkwVkR1VdV3zQqp6J3AnwIQJEzrdzxIRCO2NVlwB9b/tttNbUoKZHmjILXGcm9urYYbehW3DI7cOJBHffLjxjWf6AHDjL0cQjy3hnf9VEY9uKrOhvCPmW2L5LA6euB9HnHWwq/5mMyi6FGg+AXxY5r3mLAEmqWpSVRcAX+IIfE6QkmPIyWwG/2goOYGe0EU0FDNGzIsJVViz0o/dyvYq6TSsXLzlLK10ytGIeNTHjeePIB7tnGb8+ZXf88t/nIVluTvRMBtr04FxIjJaRILAycCkFmWexmmdIyI1OCEY95dBZXDGaXOwDUDqc4g+jrnhDAYPI0OcFb1ZkIgJF39/LL89eQzRRot0swiRKjx9Vw2NDVs2HjcX/87tQvqt4/dip/3GZ12+M3Qo6KqaAs4DpgCfAY+q6mwRuUZEjsoUmwKsEZE5wGvAr1V1TU48BjS1iNzMdrExYm4w5IMcrmnU5ZnV1e2zaG6Iy344ii9nlbLwixLOPWRrXnuyD6uWBljwWYiGdRb/+sMQaDX3Z9d68cGSIFc8/KsufTcbsjqrqjoZmNzivSub/a3AhZl/eSAB4jPaW7T4Mv/Mjn+GtsjlmpKOheHrz0Ocf8TWJOKC2o44L18Y4sZfOpM1AkGba+//CrfDr7dPv971MEtzvLNSNIOmlzktdDULVYoWk1zBUCRoK9quCpPv70c8am0U89Z49j81rvvzjwv/67rN5nhnLxdNo+svzewjbGNWjRYxvj6QjoCaFrqh+LDT8OpT1c3eUTZviStllWnefqHK9bpnvjyLtSvX0XdgdYdlu4JnWujadDfEpuB0442YFzX+nYyYG4oCEWcAs6neoqneItJgccWpo2moa96W3STmG+aar6sNkIvZbratnDT4p5w4+EyevWMK2loXoht4poVO5H7Msn+PEHu00B40w8z57u2sq/Xzt0uGYaeFj94uJxFre1ZKeyEYN6lbuZ47L74PO21z9LmHuWbXMy10tLFAFUuLv80cdW9hxLw3k0zAW89X8e6LVbz/SiWJmEWx3MOxSJz7rn7c1Va6dwQ9uA+F+SECIBUg5RA+FsrOAWsYEC6ALwaDoSM26GO0yWLtygD33TSosA61Q8PaBpJx97Zi9kzIRSouQRPTQPO5cx9AEkLHADYkpgFpCO4H8Ted+a4Gg6GomDm1nLpaP59MK+PVp/oQjxZvQu+q/lUEQu7lwvWOoPuHQc3/0NXfA2rzWLNuGRMuqhixwdAeG3LTen+TLIBoEwRCzmCnZbHF1rUN64Tf/3h0JrRS3IRKQ/z4Dyc7e1S5hGcEHUB8/VBJm7CowZA1Sk8Rc1X42UHbEm+y2Plb9Wy9c5Qx46NU9rEJl6SJxyyeu7cmM+hZ3AwYWcOPrz2Fg07dz1W7nhJ0tdcWIORiyB9hnN0IzRPbsDmq8MefjWDFQmdB4WtP9eO1pwrsVBfwB3x8/5dH8NMbTnW1Zb6B4u+XNCddixmM7MnEKC4xL/6WXm/h9t8NYuqz1VmVtXzFK2upZJpJt0/h6f97ISf2i/fIW8M/0txjOSWAyf3ZDGsrPNaJ9RyqrS/Pb07dah+T7u5cVstiFvV4JM5jf2m5Ya07FO9Rt4JICMp/RX4yu/dGAiDDCu1E8WDPxaxKzi2qsOCzMHYaEnHZYk/yVNLZd6Uza0DstI2dbmVz8yKifk1u1tV4StABpPQUTKupA7osyhHQ+a66YjCoOjk5163xkWiWfS8eg6f+1Y+fH7QNx2y9E+cesjXrVvuJNFgkE46Yf/lxKQ/fOrBwzueIPgMqScTc3x7De8qY/AzH7d6Ul7EzlIJV3lMmNhg8zqfvlXHDecNZvSy4MbRi+ZSSMptwqc2aFc4c7HgUFn0Z5kd7bsde361n4LAEX35cyqxpZfTEOGvt8jouPeQP3PT61b132iKAphcDJkF06wSR/i+jq/cptCOGXkoyIbw1uZJvHlLP7BmlXPHDMaRTmwcC7LRkNstq7fsWbz5XnR9nu4MPyivLSMaT2Gmlol85jeuaSESya3Wn4inmzlzArKlz2Gn/7V1zy1OCrhqH+t8X2o0ixQ9lP0V8NShBencPJowzW6Y3n4P8kkrB25Mr+fulw2la76OkPE200dfhgKdX8YlFRd9yVn69ikAoQLQhip1MI9LxIO8GUvEkX874qvcKOvG3cPZCLwTFvmtfChIfYq8+lF4vZBIGqwLSiwvtSY9F1dn4yh9wVmymU8K2u0ZBQVWINHhLWjpLOmWzfP5KAOJZtspb4g/6GTDc3WQw3hoU1Uj2jz9XKZ4d2tolOQ3SOcvN7R10nRHzHKK20yIPhhwxBwiFleqaFEf/JJ/bcnibQCjA3kfv7qpNbwl6cC8KM43MpnA9A4OhuFi5JEA8umUDJxRW9jiolcC4S+RiZWWhsCzh5qnXEHRxYy7wmKCLrz+UX4AnWssGQw8knYan7uqPv5WIim3DysXBnNXtdnafQhEsCXDZgxcwavxw1217StABrPIzIXRgod0wGHolqjD12SqO224HTt5pPA/9fQDpzBTZREy49TdDC+tgESOWsMt3duT/3rue/U/8Zk7q8JSgq9pofCrYglktajDkn2TcorTCJpW0qFsd4MFbBnLTr4YTiwi3/24oDevdDSEUErcjPKrK7x69kNE7jHDXcDM8I+iqKXTtmWjd2ZB8BbNyxmDoHquW+km1kiwnGRfq6yy0lWGjWMRi2YJN+/0kYhavPtGHE3bYnikPuTtjo9C4vh+MwsQx5/Lk3593124zPCPoxCZD8j2MkBsM3UMVJt/fl79eNLzVRBC+gPLp++WsXh4gFnGaqakkxCLCXy8ajt0ikbKqkIj1vB5zOuX+RIim9RHuvuwhXrr3Dddtg4fmoWv0WcC93HsGQ2+kbrWP268YwtsvVLPzPo2tzgK2LPD7lbO/vQ2HnryGXfdvZOXiIM/cXcOiuWb76u4Sj8T5zxUPcfCP9nfdtmcEHek5sTmDId+sWBzgyh+NZvnXQVIpCzstfPp+GT7/looebbJ49ck+RBp8PHnXAJ68q3Nb1xo6ZvWSNcz98CvG7TrGVbueCblIyQl46fljMBQLtg2/OWEsi+aGScR92GknZBKP+vjrRcOJRYVkZrFjtMnisw9KeWNSdeEc7iXcecl9rtv0jkKGDoDwCRB7qNCeGAxFjaqzmlMySZTffK6KlYuDqG45beP1Z/ow95NSDjmllup+ad5+oYrpr1RuESc3uM/n789z3aZnBF1EkOqrsVfPgvTsQrtjMHSBIOD+HtjNUYW1q3zcf/Mg4hGLi25ZzG2XD213x4ylXwW5+zozf7wQqGrv3j5X+tyE1n4fiLpodGAm+XTMPZsGw0b8ENwDNAjJ112w1/qDwU5DpMninIO3YV1tgEDQZvvdm4hHOtqLyLTGC0E6mWLmK5+w60HfcM1mVjF0ETlURL4QkXkicmk75Y4TERWRCa552JLUQlzfz0VsGDAdSk7CyavpmaEFgydIAVWQfNsFWwJStdk7a1b4aaq3ePuFKs797tasq3UmECQTwsy3ypGeN6PQM4jV9sMyGU8x9fFprtbXYQtdRHzAbcDBwBJguohMUtU5LcpVAL8E3nPVwxZo/Q24Pn3RboLIfyD6jPu2DQaAhDtZ3lVh1cqBVFfW4g8q01+t4PentT1T4uO3y4k2mgZKNgweO5CxO4/i/ec/JJ1KuzIPXe12Yl0CwRJ3977JJuSyBzBPVb8CEJGHgaOBOS3KXQvcAPzaVQ9bYi/MgdEoxP6HCbkYip14FO6/YR0vPboj4VI7s5pTaT1sItTXmem+2bJ8/kpql6yhtLKUYdsMYfbbn+c2BYLCvt/f01WT2Ty6hwLNN5deknlvIyKyKzBcVdtd0yoiZ4nIDBGZsXr16k47C4BV3bXvtYtCalkO7BoM7hIuVfY/ah1qC9FGi1jEh4mBu0cynqJhTQOfTfsyL/lsQqWhjgt1gm73xUTEAm4GLuqorKreqaoTVHVC//79u1Zh2a+69r0OWZcjuwaDe9g2RBs3BMV7r5C7vs9KM2xbsdP5yX8wcGSNq/ayOStLgeYb9w7LvLeBCmAH4HUR+RrYC5iUq4FRq+xE8O+WC9MGQ9HRcrphPCo8f1/P2gSrS/SAvdED4QDV/as6LtgJsomhTwfGichoHCE/GfjBhg9VdT2w8TEjIq8DF6vqDFc93VCf3QCpj3Nh2mAoGlQhncpsfBUXBPAHlCf+OYCZb1Zkb0igvLqUxrpIznwtBHZ7g40eYZsJY1232aGgq2pKRM4DpuBsQn63qs4WkWuAGao6yXWv2vOn4f8oTBq6YqHYk1UbuoKdxpmRKE4r/L83DmTS3TWIZbHTNxuoqE7z8TvlrF3ZuUFOv99HtCGO5bPyFkYwZMcXM+azcM5iRrqYuUgKldZpwoQJOmNG5xrxduQZqP8NJr+nwYtsuNVaWxgYjwm/PHIrapcHaVzna3WZvqFnYfksDvnxgVx458869T0R+UBVWw1pe2alqCPmv8OIucHLpJIQaDH1WBWWfx1kwZzSwjhlKAh22mbJl+7OrvPOioPGmzHzxA1eRgTWrgqwrtbnbKClkErBikUBfjdxdKHdM+SZQCjAN/bf3lWbnmihqyrYywvthsHQbUor0hy/3Y7UDIkzZnyMulUB5s4qoTdPQeyNiAgl5WGOPvdQV+16QtBFBLUGG1E3FD0LPguzdpWfcd+IUtln83SJKxYFueLUUQDULgtRu8zdRSUG77D1bmO48vGL6DMg/9MWi4PyCzMxdBN2MRQfdhou+8EY5swoxedXUgmLk85byakXrQKcKYgXHTOW2hVmKX5vJ1Qa5KJ//5wBI7q4uLIdPCPoVunRznBowzWgDYV2x2AAnDi4CFwxcTSz3iknnd4UOnns9gGM2i7G7gc28N4rFdTV+jGhld5NIOjnW8ftxegdR+bEvmcEHTKiHvkXpL4otCuGXoKq0/pevSxA/yFJLJ+z/N6XWX2fiAl1tT4+eXdzMQeIRX386ecj6T80wYqFQVS9MwehXcxSiC4hIhx/8VGcfs1JOavDU4Ku9lqwGwvthqGocScrkKqzn/gN5w1n2pRqqvolqeyTZvnCIImYxejtYvzs6iU89e/+bLNrpM2V6KmkxfKvw932p6jwoJhbPsFOF9bxvoOqOf2ak7Cs3D3YPSPoml6Nrjka7HWFdsVQtAhYQ8Fe0C0ryQQ89a/+PH9fP1YsdAYu164MsHblpgnkX80p4ZITtgLg3RcrUZODs8gRp3dVQFHf/bCdWfLlckZsm7t0f57pA2rjPzJi3puX/RvaR7sn5r6RgJ8pD/XjgZsHbhRzh9b3GwdB7Y5SvBnAaSUXgmBJEDttF7yF/tK9b3DObpfwzjPTc1aHZwSd+OsYMTfkDj+UngGlE1k8rzSzz7jBTaoHVLPLd3bI27NPLGHk+GHsfKC7i3e6SjplE48muPEnt5FK5kbLvCPolrvzNdupCMhXXYbiIUVs1Z+JyjmM2fsCwmVmeqHbxJpizJo6J28xeLGEaGOM9yfPzE+FWZJKpFjwyaKc2PZMDJ3wwdA4Ow8V2cD6LnwvBFYlaBisPpCe5bZjhhzxxUcl/OnnI1m+MAiciViCz29a6G4TqY/mtT47ZbNqUW1e6urMbpaxpjhzpn3BuF3bzgXbZT9ct5grEsW+B3oc7NVAA5ROxEuntqejCokWE19iUWH1Mj+rlgS4+NitWL4wxIZYgNpKKmHCe4Vm+LZDCu1C1nR2a+L/Xvko6XS644KdxDst9PRXhfYgO3QdNFyJ2RUy/6hCMi74Arpxnng6DZ9MK2PeJ6V87/RaUknBH1TeeLqaJ/9Vg8+nJGJmQLMYWfx5z83zG4vEWfLlckZuN8xVu94RdN92kF5YaC+yJL9dS4PD43f0Z8pDfTjtkpXsdkAD8agw5eG+PH9vX1YtDfPALQMZPDLOqqVBGur8gGYa5UbQDfnFTtuUVbm/XbJ3BN2qLLQHhiImnYIHbxlIpMHHH84atdlnFdVJACINPuZ/2vwmEk8ukjF4n9LKEmqG9HXdricCvWo3QuypQrthKDiC0wbZskVdX+cnlWi9pR1p9GGU21BMJOPJnNj1hKA7oRZzQ/ZW5n8a5tUnq5k7KwyBCcCmBT92ZlypojqFz9/6NVJS5v7gk8HQHeLRBIkciLo3Qi6+wZhBxt5HNAJXThzDFx+VYlnOoOfo8Y3sfdg2TP5vnOqaFH9+fD4hn+IPwInnruLhWwcQj24+5bCp3uxyaCguLMsi2hAlGHJ3vYMnWuhi9YXgNwvthsF12hfZ+/8yiM8+KCMe9RFt8hGL+Pj8A4t7/iisWBTi8w/LuPbMkayr9RFptDj2rNV87/RaLJ9N8x6dSbhsKDYqayqo6Fvuul1vtNABqv8Kq3YvtBcGV2k7jBZtsnjm7v4kE5u3OVQFbbYnx/RXqzhl50qGjY3TsN5H3SqzwtNQ/Jx948Sc7LroiRY6gODDS88fQ9eJRoTHbu9Pso1BzpbYtrBobtiIucEz/ONX9zjbILiMdwTdKgf/uEK7YcgxqvDaU9U8eMtATCYFQ09lfW0Dlx3+RxZ+tsRVu54RdACp+hNIGU4SA0PHeC92nEzAoi9LmsW9vXcMXcHyeepWNLhAIpbgsRufcdWmp64iCYyHqr9mXnnK9cIg7i9cyDWphMXaVb0vtNbZvUAMxYN0cZ93tZWvXN510VN3jmoK1v8GN1KM9Qp0XaE9IJ0Csdg47TARE159sg/vv1JJv4FJjjxtDaO2jQFOrs5kUpg2xWxfbPAO2o3EGW73P70l6In3QJsK7YaHKOyCmmQC/vWHweywR4SKPilef6aKqZP6kEoK8agPsZQpj/Tll39exL6H17N6WZBrzxxFIlb8va/yPmU01plr0dA9apfVuWrPM4Ku6WWw7gJM69w7TLqnH8/8uz9P/6t5O0TZtE2tkIgJN54/kntvTLBycRCvxMyNmBvcIFTi7nigdwR9/WWgXUk8Ycg3sYgjyv+9YXAri3paz825cnGolfcNhp6LWMKhPznQVZtZ9W1F5FAR+UJE5onIpa18fqGIzBGRWSLyioiMdNNJ1TQkprlp0tAN0in44PVy3phU1eoA5vP39eXYbXfYYgm+wWDYRDAc4PgLv+eqzQ5b6CLiA24DDgaWANNFZJKqNp8VPxOYoKoREfk58GfgJLecVE1j5iMXBws+C3PpSWNIxCxUIZUUTvrFSiZetGpjma/mhEmnvBE6MRgKRb8hfQiG3Q25ZNNC3wOYp6pfqWoCeBg4unkBVX1NVSOZl+8CrqbhEDFiXgzYNlxx6mjW1fqJNDr7qyQTFo/dPoAPpzr7Unz9eZiXH+uHV2LhBkMhEEs48JRvuW43mxj6UGBxs9dLgD3bKX8G8EJrH4jIWcBZACNGjMjSRRAJob6tIf1la59iWu/uUrvCz7xZpSRT8L8H+7F4bogx42Psc9g6mup9tBTreNTill+PZZ8jGnj+v+5vOGQwFALLEmw7N9oyYHgNJ158lOt2XR0UFZFTgQnA/q19rqp3AncCTJgwoVNnSqqvR9ecBLTcQ9iIuVvYNtxy8TBee6oPYimppGRCJ8KqJUFmvFaB1eqe48LKxfDkHRX5dtnQEaa902VyJeaWz2K/E/emtKLEddvZCPpSYHiz18My722GiBwEXA7sr6pxd9xrZj+wA2pWh7qOKqxd6ae6JsX9Nw/kpcf6Yqe3DJeoCsmEIEmjDl7BF7BIJ80K1GLDTtvUr67Pie1sBH06ME5ERuMI+cnAD5oXEJFdgH8Ch6rqqi1NdB9NLcTMQXcfESgpt/nhbuOpW91xIgjLAl/AJhGTDssaCkt7Ym75LLPdQIEIlgSZcMjOObHdYZNXVVPAecAU4DPgUVWdLSLXiMiGINCNQDnwmIh8JCKTXPdUE4CZBpcLVGH73bNbKFNenaLfwCRGzL2NqulpdQmBmmF9GTRqAL5A1/QoEU3w7uQPsG33H6hZxTBUdbKqbq2qY1X1usx7V6rqpMzfB6nqQFXdOfMvB9H+sSCVrps1OK30UIlNxyKtrF8TYPnCri0CCpeF6DPI7NNSDPj8pnHUJRTWLl/HNw4Yj2V1vVHzxiPTePYfL7romINngtIiVmanRc+47Bl8fuWDN7IZ0OxeqzzWFKduxXp8AR8lFWHG7jySmmF9Ka0qZdDoAabRn0f2OcZk/+oqdtrmxXteJxlPddlGKpHizkvucz1RtGeW/gPQ9E9Msuj2UYWP3ynjxUecwc0Dv1/HHt9pQNVZ4bl2pZ/q/mlCYSWVglRC+O+fB7GuNn/ZftLJNNFkmvkfLdz4XmR9pJ1vGNxm2nMfFNqFXk8iluDFe17nyLMPds2mZwRdk3Mg+U6h3Sh67rxmMJPv60csYgHCtCmV7LRvI8PHxnnvpQqWzA+z2wH1fOuI9UQjFi8/1pd5n5R2qS7xCT6fj3QybWKy+cSi2+2aRMRMMCg4Cq8/8nYvFfSY+/GmnkA6BbGY8OQ/+zN62xjP/bdms+1nYxEf771YyXvN4hkzXqtixmvdj2XvfMAOnH3TaVy43++I1Ee7bc+QJaaT2mNwey66ZwQdTALg1vD5IRxWtt89wuU/HN3qHPKcBKcFQqUhzt/7MhJR09ozGDqLWHDEWQe5atMzI4xSchgecjev+Pyw0zcb2xDzHKHw7rMzjJgbPEcwHKB6YBUVfcoKOhCvNnz61ueu2vSMQop/DJSdU2g3Ck5boepopIclVe4hh2EoHgLhAMO2HsLE35/IAwtu58k193Dk2d8lGCpc7//p/3uBdMq9zGKeEXQAq+J8KLuk0G4UjHW1Pq45cwSL5m2+5WYqCe9OqaKnqKDlE7P/SC8n6HImH4BkLElV/wpOuPh7G7etPe/Wn1DWp2uTAlzxKZ4k2hhzzZ6nBN2hAU+63U3SafhwagXvvFDNud/dhg/eKCcZh0iDxaqlQe66dkihXXQNuxtJdw09g1yF8ma//QXXnngzyUSSaFOMiw64iroVhcuEZvl9lFW590Dx0KBohthL9LZhflWIRyzuu2kQ4OThvPonozhi4lqWLggy/dXK/MbPDQYP8/ZT7zNx7HkEgn5WLMjJ1lNZY6dsRNy7d70n6FZloZPZ540NWz18OLWc2y4fxrIFm5bcx6M+nryzf4E86x5iOQNCBkOhWLN0baFdAMDfxf1g2rTnqrV8ENgZkh8W2oucsGE156K5YWZNK2XVkhAvP96H9Wt6zpTN7ffZhjnvfIkJkhsMcOAp+7pqz1OCbttNELmn0G7kjFefrOaZu/vxxcyemfWntLKEupXrzapSQ68hGAqABYnolnu2iPTieegANP2LnhA/39ASb/66brWfv148vMeKOUCkPsqyeSsK7YbBA4glzmwnDxMMBzj0jO+wzzF74A9u2Xa2fBaT//WKq3V6qoVOdEqhPeg2dhoWfB7i6X/3Z6+D66muSfHmc5VEGn2bibwBkz6tl+P12U6JWJIp97wKOLsrtiSdsln02RJX6/SMoGtqMdhfFdqNLpFKQlO9j8b1Fn88ZyTzZpUCwosP9yu0a51GRDjx0mN45u+TiTW5nmlwc7x9Pxu6geYon2d7iCWu1xtvZxM0f9DHtnuOc7U+7wh6w/V49Q7/cGoFv5s4ptBuuIKqMuOFmfQZVM3y+SsL7Y7B4Bp57RAKhEpCHHfBka6a9Yygk3gbLwp6tMnilSeqC+2Gq8z/6OtCu2AwuI6dz16Bwi9u/yn9h7nbS/fQoGg4z/W1fmriUeHVJ6t58G8DmP5qxca54qrOvHHVTf+iTRYfvVXO1El98ui3oTnSjTRhBkO2dOU6u/u3D7juh3da6CXHQeSuPFa45WyapQuCXHj0VsSjFvGoRbDEZujoODc8Op/Hbh/AY//oz4hxMfY9Yj2hsDLjtUo+fqeMnrLHihcpRCzW0PvoynW2ZtlaapetpWZIX9f88I6gB7YHfBRymeiN549g/Vo/ajsCHWvysWhumPtvGsRLj/XFTlt8/XkpX39euM1+DAaDN/D5fUQb3E0M45mQi2gMcH8HtrZItVgH0FRv8eXHJRvFfAPJuMVz9/ajqd5kUTcYDNmTTtsMGjPQVZueEXRCewM5niaXIZ2CVHLLMElbe+ikkt45jQaDoTjw+SymT57pqk3vKJFGyGUsWhVWLfVTX+fj8w9LufPqIcQiQjoT4bH8yvCt4hTTTBuvr6Qz9DwmHLJzoV0oGIFQ5yLYiViSD1/5xFUfvBNDT84BCYM25cS8bcNlPxjNknkl7LhXI599WMbcWaV87/RaqmtSTJtSyZL5IYppgNPrK+kMPY8ZUz4qtAt5JVQSJJ22sW2bUGmIVDKd9QBpMBygZqi7M+C8I+i+YeSqdWzb8OXHJSye6wxmzppWDghfflzKTb8akZM6840/6G91+XFLcrFazmDoiQRLggzfbiiLPltKKpGisa5zjU2xLA6auL+rPnkn5BLYOSPqnWsht9x327Y3/zvSYDH91QouOLL5EtziaYV3F8snHHDSNzn2gsOzOiwj5g57HLZLm2MmBgNAeXUZS75Y1qXsSmXVpVw76TeuTlkEDwm6iEDJRCD7vcHnzw6xfq2PaJNzmJFGi5VLArz+TCUAa1b6uebMkVz5o9EUq4j7g34CoUCru7VlQ2W/Ci578AIWzl5aTOH/omfGix+3mZDbUPzkY0FZ0/qmbu1ntOO3tnPRGwfPhFzs6PPQcB2Q/dPwjiuH8cVHJex/1HqGjo3x1ewS3p5cRUmZzTcPnUOkUZj5ZgXFKOa+gI8jzjqIbfcYx37H74Uv4OO4fj8h0sl5q+trG3jp3jeY+cqsHHnaM7HT3t+muTeTj55mextvdfjdpgSfvz+PHfbZ1kWPPCToNN4EtJ4dWxUWzQ3x9Wdh+g5Msf0eTVgWzPukhHjUx4uPbN6taVhncfz47YlHLYpRzAHSyTSz3/6CH197CqESJ/VcZ8UcnAv7pjP/YQTKUFSIT7Asi3Syl+STbEEqmcLKQS/CO4KeXtbq22rD2d8ex8IvSwCwfMo+h63nsjsW0W9Qksi81hf8xKPFvxBo4ezF/O3nd3L5Q7/qlh0j5r0PX8BX1GKptnoo4JsbBo8d5LrNrE6piBwqIl+IyDwRubSVz0Mi8kjm8/dEZJTrnkp1q2+vXh5g6YIwTktbsNMWbz5XzZSH+/DDC1ci4t1AaCqZ5q0n3yOVdGanlFWZLQVcR9xP1FsM2Kkif4grRf3AyTU+v49wWajjgp2kQ0EXER9wG3AYMB44RUTGtyh2BlCnqlsBfwVucNtRwods8VYsItxz/aBWVmoK//jdUOyUen5gy7aVdMq58Pc7fq8Ce5Mfxu+9NaGS3G/zYPksdthnW3w9UNBV1ew0WaT4AhZ7HL4LJWXu7yCbTQt9D2Ceqn6lqgngYeDoFmWOBv6b+ftx4Dsi7k76kvLzAB9rV/kzqzoD3HrpMF55ovVpP7YNt17W+WmObtN3UDWhkiAlFWHCZSHG7TqGX911Nufccjq7HrRjh98fstWgjTH0o845FJ+/5/ZTQ6Uhfvfohfzt7eu4bvJljN5xZM7que753/K/xMMMGTuoW4NbxYyIEAgHKK0sIVweZsR2wzj9Dyd3ecZUb2Dk9sMIhnPTmAiXhQiXhRiz4ygu/vc5Oakjm192KLC42eslwJ5tlVHVlIisB/oBtc0LichZwFkAI0Z0bsGO+Pqj5Rdz608e453/ldHRsygZ95HsxIwiEdptzYtIp7LVl5SH+O0DF7D39yaw4NNFLPhkEUPHDWbr3caw4Vk3ZOwg5rw7l1hj64O9AKdffdLGv7faZTQ//sMp/OeKh0hn06UWGLvTaOZ/tCBrv8GZX3vqlcfzwUsfM/2Fj7L/ooDPb5FOZtfdt/wWliWkk2lCpSH2PGI39j3WubR22n977vz4L/z++3/mnWemd8r/9hj9jRFc/dQlDB7tbIoULAm0v5iqs2lsiigPar8hfbjt/ev5/P159B3cZ+O1d8JFR/HSva/z3B0vsnJhLRV9yli9dC3J2JaZ6bM9ns4sSAuEA4hIh/O3LUuw/L6sFsS1RnnfMhrXdrzYRywhXBbm9unXU1lTwY/GnkcynmhVD0KlIU646EiqB1Rz9+UPEqnPbqJCZU0F59/+UwaPHsC4XTdpgNtIRyIlIscDh6rqmZnXE4E9VfW8ZmU+zZRZknk9P1OmtjWbABMmTNAZM2Z02uFZrz3HZUfeSzya5fLaUIB0Ot2mAPoDFufeegY7H7ADiDD18Wm8fO8brFy4mkTmAvcH/QwcUcPFd5/DX874B0vnLt9kIHPBh0pDgBMeOeHXR/OTa0/p0Ld0Os2ZO1zI8vkrWvVvyNiB3PPlrVv8+KsW1zL1sWn89/ePtDoPtqQ8TLAkyF9evYqR44dxyvCzWbOsrk0/QqUh4pE4/oCPA07eh4v/fQ4+vxOG+OTNz/j7uXfx9ezFzqG2cdoDIT+n/+EUHrruCRrXRbYs0EwYRISqmgr+8sbVvPXEuzSui7DXkbvxjf3Gb3GsiXiSP5z8V6a1IuoDR/Wnoa6RyPrsbqrSijD/+eLv9B20abn1Z+/N5dffuWqLVrrPZzFw1ABGbj8My2fxwYsfE4/EWz1+EWHszqM4//YzGTxmIHM/XMDVx/2FdDJFKpl2bfWtc24cOy398Pmtza6hUGmIn97wQ44+97AO7Tatb+LUMefStK5po13LEir6VbDHYbswbdIMIo1R7JSNCPgCfkrKQkQbYwRCASr6lrPP9/dg+29uy3+ueIhl81Zg+ayNocLmlPcp57GVd/Hl9PlcP/FW1ixbi9pKVf9K1tfWk4w74m35LEorS1BbaVrfyvXUAb+59zx22Hc7frbLr9v8vtOD8bPPMXvwo9+fyLCthwDw9ezF3Pjj25j/8deg0GdQNT6/xeDRAzj50u+z28E7AfDU3yfz78seJB5pp+WYSTV39VO/3vi97iIiH6jqhFY/y0LQ9wauUtVDMq9/C6Cqf2pWZkqmzDQR8QMrgP7ajvGuCjrA83e9xB0X3YtlCalEinB5mGQ0iapSUhGmvq6RYDCAnbY59oIj+PYPvsUD1z3Bu899QKwptlGYRu0wnOsmX8aAYTWb2U8lUzz198k8f+fLJGJJ9j9xb35w2bFU9CkHoH5tA8lEiiWfL6O8TxkDR/bnvec/JBlPsvthu9BvcPb7M9SvaeAfF97Daw+/TTqZxue38Af8DBhRwx9fuJxBowa0+V1V5Z1JM/j0zTlst9c4LJ+PBbMWMWjMAPY7fq+NoZql85ZzycHXsG7leuy0TSqZJhDys9f3JnDGH3/I0K06Hm1PxJP4Az6ijTHmf/Q1qWSKpXNX0LQ+wg7f2pbt994GEeGrWQu58pgbWL+6HhEhVBrizOt/yFN/m8yiz5eAwuhvjOS3D/ySYeMGZ32envzb89z1m/sBp0XVf2g/rp9yBetW13PFkX8k1hQnEU+COjM8Dp64H8O3Hcrz/3yZRDzJPsfszmlXn7TxN2zOA9c9wYPXPYHlszaK79VP/4Zdv7PjxvP88euzee3ht4hHEnz48izikQS2baO2sscRu3L5gxdsfAgCLJu/gmfveJHl81eyy0E7cuAp+3DFEX/is3fnblb3TgeO56hzDiUVT3HXpQ844qNKKpkiXBoi2hRHLGHImIFc/tAFDBjZH8tnkYgmeP3Rd0hEEnz7h/vy4B+f5H//fhVfwIedVo6/6EhOu+qkrFuCX89ezPUT/86iOUtQYNxuY/jt/eczePRAVJX3J3/IKw++RSDo57unHcBOB2zfpq1YJM7Khav58KWP+fdlD+H3W6TTNv2G9OVPL1zO4MyWsarK6iVrCIYDVNVU8vL9U3nspknU1zay60E7cvo1J7F6yVouP+KPpJKpzR66G3rMwZLAxvPRZ2A12+y+FWfdeCpDt3LEOZ1Oc/81j/PKg29ufCDXrVhHuCzEYWd+hzP/9MM2QyyRhiiWzyJc2vrgpary+M3P8sB1TxCPJCgpD7P7obtQ0beMaEOMSEOUIWMHcuTZ3914zG7QXUH3A18C3wGWAtOBH6jq7GZlzgV2VNWficjJwLGqemJ7drsj6ACJWIIFnyyisl/FFicr2hhlzbI6aob12+LHWF9bz8qFqxm61SDKqsq6XH8uaKqP8MX786jsV8HYnUe52i1TVT5790vq1zQyfu+tqexX4Zrt1ur6evZi0sk0o78xAp/PEbq6VeuxLKGqprJLdpvqI3z+3lwq+pZv1m1NJVPMemMO0aY4o7YfRs3QvhsfZtmyeskaZkz5iHBZmL2O3JWS8pI2y6bTaWa+8im1S9aw7Z7jGLX98KzrWThnMe+/MJN0Ms0BJ++z2QM7nU7z0aufsnb5Orbbe2uGjRvMmuV1qG1TM7Tj3JORhii1S9cyYERNmyLUEetr6xFLqOzrzvURbYrx5fT5lFWXMnanrl3TiViCGS9+vFEgK6rL8AX89BvSh0/f+pxELMlOB2xPaUXbv1lzbNvGstwbi7Jtm2hDlJKKElfttkW3BD1j4HDgFpyUQXer6nUicg0wQ1UniUgYuA/YBVgLnKyqX7Vns7uCbjAYDL2R9gQ9q+FuVZ0MTG7x3pXN/o4BJ3THSYPBYDB0j547B85gMBh6GUbQDQaDoYdgBN1gMBh6CEbQDQaDoYeQ1SyXnFQsshpY2MWv19BiFWovwBxz78Acc++gO8c8UlX7t/ZBwQS9O4jIjLam7fRUzDH3Dswx9w5ydcwm5GIwGAw9BCPoBoPB0EPwqqDfWWgHCoA55t6BOebeQU6O2ZMxdIPBYDBsiVdb6AaDwWBogRF0g8Fg6CEUtaAXRXLqPJPFMV8oInNEZJaIvCIiucnTlkc6OuZm5Y4TERURz09xy+aYReTEzG89W0QezLePbpPFtT1CRF4TkZmZ6/vwQvjpFiJyt4isyiQAau1zEZG/Z87HLBHZtduVqmpR/sPZqnc+MAYIAh8D41uUOQe4I/P3ycAjhfY7D8d8IFCa+fvnveGYM+UqgKnAu8CEQvudh995HDAT6JN5PaDQfufhmO8Efp75ezzwdaH97uYx7wfsCnzaxueHAy/g5PPaC3ivu3UWcwu9KJJT55kOj1lVX1PVDTm13gWG5dlHt8nmdwa4FrgBaDsBq3fI5ph/CtymqnUAqroqzz66TTbHrMCG7CdVwLI8+uc6qjoVJz9EWxwN3KsO7wLVIpJ9Gq9WKGZBby059dC2yqhqCtiQnNqrZHPMzTkD5wnvZTo85kxXdLiqPp9Px3JINr/z1sDWIvK2iLwrIofmzbvckM0xXwWcKiJLcPIv/CI/rhWMzt7vHZJVggtD8SEipwITgP0L7UsuERELuBk4vcCu5Bs/TtjlAJxe2FQR2VFV1xXSqRxzCnCPqt6UyWV8n4jsoKqtZ3g3bEExt9CXAs2TNQ7LvNdqmUzu0ypgTV68yw3ZHDMichBwOXCUqraTctwTdHTMFcAOwOsi8jVOrHGSxwdGs/mdlwCTVDWpqgtw8vqOy5N/uSCbYz4DeBRAVacBYZxNrHoqWd3vnaGYBX06ME5ERotIEGfQc1KLMpOA0zJ/Hw+8qpnRBo/S4TGLyC7AP3HE3OtxVejgmFV1varWqOooVR2FM25wlKp6OSFtNtf20zitc0SkBicE026e3iInm2NehJOMHhHZDkfQV+fVy/wyCfhRZrbLXsB6VV3eLYuFHgnuYJT4cJyWyXzg8sx71+Dc0OD84I8B84D3gTGF9jkPx/wysBL4KPNvUqF9zvUxtyj7Oh6f5ZLl7yw4oaY5wCc4idcL7neOj3k88DbODJiPgO8W2uduHu9DwHIgidPjOgP4GfCzZr/xbZnz8Ykb17VZ+m8wGAw9hGIOuRgMBoOhExhBNxgMhh6CEXSDwWDoIRhBNxgMhh6CEXSDwWDoIRhBNxgMhh6CEXSDwWDoIfw/QGyeKJ+w/F4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_x = [np.random.uniform(low=0, high=1) for _ in range(10_000)]\n",
    "X_y = [np.random.uniform(low=0, high=1) for _ in range(10_000)]\n",
    "X = np.array([X_x, X_y]).T\n",
    "Y = [torch.argmax(classify(x, true_phi, true_b)).item() for x in X]\n",
    "plt.scatter(X_x, X_y, c=Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 861,
   "id": "fb38cb57",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alex\\AppData\\Local\\Temp\\ipykernel_39092\\828025484.py:27: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  reward = u @ softmax(phi @ X_hat + b)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x247f58e1280>]"
      ]
     },
     "execution_count": 861,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_new = torch.tensor([0.5, 0.2])\n",
    "u = torch.tensor([0.3, 0])\n",
    "x_prime = softmax_gragent(x_new, true_phi, true_b, u).detach()\n",
    "\n",
    "plt.gca().set_aspect('equal')\n",
    "plt.scatter(X_x, X_y, c=Y)\n",
    "plt.plot(x_new[0], x_new[1], marker=\"o\", markersize=10, markeredgecolor=\"red\", markerfacecolor=\"red\")\n",
    "plt.plot(x_prime[0], x_prime[1], marker=\"o\", markersize=10, markeredgecolor=\"red\", markerfacecolor=\"red\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 860,
   "id": "557abba6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.5216, 0.1656])"
      ]
     },
     "execution_count": 860,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_prime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 870,
   "id": "dc2b9506",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5.3704, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 870,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake_phi = torch.rand(2,2)\n",
    "fake_phi.requires_grad_(True)\n",
    "res = torch.sum(fake_phi + fake_phi[:,1] * 2)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 871,
   "id": "22e9ecf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "res.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 878,
   "id": "840b0b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 5\n",
    "Xs = torch.rand((n, d))\n",
    "W = torch.rand((d, m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 880,
   "id": "39c9da7f",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (5) must match the size of tensor b (2) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[1;32mIn [880]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43ml1norm_phi\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mW\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mu\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [877]\u001b[0m, in \u001b[0;36ml1norm_phi\u001b[1;34m(Xs, W, u)\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m300\u001b[39m):\n\u001b[0;32m     61\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 62\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[43ml1norm_decision_maker_criterion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXs_hat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mXs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mphi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mW\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mu\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     63\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m     64\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "Input \u001b[1;32mIn [877]\u001b[0m, in \u001b[0;36ml1norm_decision_maker_criterion\u001b[1;34m(Xs_hat, Xs, phi, b, W, u)\u001b[0m\n\u001b[0;32m     36\u001b[0m d, m \u001b[38;5;241m=\u001b[39m W\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m     37\u001b[0m one_m \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mones(m)\n\u001b[1;32m---> 38\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[43mphi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mXs_hat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m \u001b[38;5;66;03m# md @ dn + m --> mn\u001b[39;00m\n\u001b[0;32m     39\u001b[0m penalty \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     40\u001b[0m reward \u001b[38;5;241m=\u001b[39m X \u001b[38;5;241m@\u001b[39m (W \u001b[38;5;241m@\u001b[39m action \u001b[38;5;241m/\u001b[39m (one_m \u001b[38;5;241m@\u001b[39m action)) \u001b[38;5;66;03m# nd @ (dm @ mn / (m @ mn)) --> n\u001b[39;00m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: The size of tensor a (5) must match the size of tensor b (2) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "l1norm_phi(Xs, W, u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 886,
   "id": "f5e0619e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4646, 0.8714, 0.9069, 0.7962, 0.3983],\n",
       "        [0.3173, 0.5402, 0.5802, 0.4952, 0.2943]])"
      ]
     },
     "execution_count": 886,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phi @ Xs.T + b.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "695c183f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
