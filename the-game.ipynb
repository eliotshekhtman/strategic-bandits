{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "395e3ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from optimization import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d014d985",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(d):\n",
    "    return torch.concat((torch.rand(d), torch.ones(1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f376db55",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_attempts = 2\n",
    "agent_iters = 200\n",
    "dm_attempts = 6\n",
    "dm_iters = 2000\n",
    "temperature = 0.02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6662f1ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alex\\Desktop\\academics\\strat-bandits\\strategic-bandits\\optimization.py:93: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matricesor `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at  C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\TensorShape.cpp:2318.)\n",
      "  return softmax( phi @ x.T , temp=temp)\n"
     ]
    }
   ],
   "source": [
    "m = 2\n",
    "d = 2\n",
    "u = torch.tensor([0.15, 0.1])\n",
    "W = torch.tensor([[1., 1/np.sqrt(5)], [0., 2/np.sqrt(5)], [0.2, 0.0]], dtype=torch.float32)\n",
    "phi_opt = torch.tensor([[1., 0., 0.2], [1/np.sqrt(5), 2/np.sqrt(5), 0.]], dtype=torch.float32)\n",
    "Xs = []\n",
    "X_hats = []\n",
    "xWs = []\n",
    "phi = torch.rand((m, d + 1))\n",
    "x = sample(d)\n",
    "x_hat = gragent(x, phi, u, attempts=agent_attempts, iters=agent_iters, temp=temperature)\n",
    "Xs.append(x)\n",
    "X_hats.append(x_hat)\n",
    "dataset = torch.stack(Xs)\n",
    "dataset_hat = torch.stack(X_hats)\n",
    "cum_dm_reward = dm_reward(dataset @ W, dataset_hat, phi, temp=temperature)\n",
    "xW = gr_xW(cum_dm_reward.item(), x_hat, phi, temp=temperature, attempts=5, iters=1_000)\n",
    "opt_cum_dm_reward = dm_reward(dataset @ W, dataset_hat, phi_opt, temp=temperature)\n",
    "rand_cum_dm_reward = dm_reward(dataset @ W, dataset_hat, torch.rand((m, d + 1)), temp=temperature)\n",
    "xWs.append(xW)\n",
    "pred_xWs = torch.stack(xWs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e062a108",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "can't optimize a non-leaf Tensor",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [12]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m phi \u001b[38;5;241m=\u001b[39m \u001b[43mgr_phi\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset_hat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mW\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mu\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattempts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdm_attempts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdm_iters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprev_phi\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mphi\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# dataset @ W\u001b[39;00m\n\u001b[0;32m      2\u001b[0m x \u001b[38;5;241m=\u001b[39m sample(d)\n\u001b[0;32m      3\u001b[0m x_hat \u001b[38;5;241m=\u001b[39m gragent(x, phi, u, attempts\u001b[38;5;241m=\u001b[39magent_attempts, iters\u001b[38;5;241m=\u001b[39magent_iters, temp\u001b[38;5;241m=\u001b[39mtemperature)\n",
      "File \u001b[1;32m~\\Desktop\\academics\\strat-bandits\\strategic-bandits\\optimization.py:144\u001b[0m, in \u001b[0;36mgr_phi\u001b[1;34m(Xhats, xWs, u, prev_phi, temp, attempts, iters)\u001b[0m\n\u001b[0;32m    142\u001b[0m best_reward \u001b[38;5;241m=\u001b[39m dm_reward(xWs\u001b[38;5;241m=\u001b[39mxWs, x_hats\u001b[38;5;241m=\u001b[39mXhats, phi\u001b[38;5;241m=\u001b[39mphi, temp\u001b[38;5;241m=\u001b[39mtemp)\n\u001b[0;32m    143\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(attempts):\n\u001b[1;32m--> 144\u001b[0m     optimizer \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mAdam\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mphi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.0001\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    145\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(iters), position\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, leave\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m    146\u001b[0m         optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\gs_tf\\lib\\site-packages\\torch\\optim\\adam.py:81\u001b[0m, in \u001b[0;36mAdam.__init__\u001b[1;34m(self, params, lr, betas, eps, weight_decay, amsgrad, maximize)\u001b[0m\n\u001b[0;32m     78\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid weight_decay value: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(weight_decay))\n\u001b[0;32m     79\u001b[0m defaults \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(lr\u001b[38;5;241m=\u001b[39mlr, betas\u001b[38;5;241m=\u001b[39mbetas, eps\u001b[38;5;241m=\u001b[39meps,\n\u001b[0;32m     80\u001b[0m                 weight_decay\u001b[38;5;241m=\u001b[39mweight_decay, amsgrad\u001b[38;5;241m=\u001b[39mamsgrad, maximize\u001b[38;5;241m=\u001b[39mmaximize)\n\u001b[1;32m---> 81\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mAdam\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefaults\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\gs_tf\\lib\\site-packages\\torch\\optim\\optimizer.py:54\u001b[0m, in \u001b[0;36mOptimizer.__init__\u001b[1;34m(self, params, defaults)\u001b[0m\n\u001b[0;32m     51\u001b[0m     param_groups \u001b[38;5;241m=\u001b[39m [{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparams\u001b[39m\u001b[38;5;124m'\u001b[39m: param_groups}]\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m param_group \u001b[38;5;129;01min\u001b[39;00m param_groups:\n\u001b[1;32m---> 54\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_param_group\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam_group\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\gs_tf\\lib\\site-packages\\torch\\optim\\optimizer.py:269\u001b[0m, in \u001b[0;36mOptimizer.add_param_group\u001b[1;34m(self, param_group)\u001b[0m\n\u001b[0;32m    266\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moptimizer can only optimize Tensors, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    267\u001b[0m                         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut one of the params is \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m torch\u001b[38;5;241m.\u001b[39mtypename(param))\n\u001b[0;32m    268\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m param\u001b[38;5;241m.\u001b[39mis_leaf:\n\u001b[1;32m--> 269\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcan\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt optimize a non-leaf Tensor\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    271\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, default \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m    272\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m default \u001b[38;5;129;01mis\u001b[39;00m required \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m param_group:\n",
      "\u001b[1;31mValueError\u001b[0m: can't optimize a non-leaf Tensor"
     ]
    }
   ],
   "source": [
    "phi = gr_phi(dataset_hat, pred_xWs, u, temp=temperature, attempts=dm_attempts, iters=dm_iters, prev_phi=phi) # dataset @ W\n",
    "x = sample(d)\n",
    "x_hat = gragent(x, phi, u, attempts=agent_attempts, iters=agent_iters, temp=temperature)\n",
    "Xs.append(x)\n",
    "X_hats.append(x_hat)\n",
    "dataset = torch.stack(Xs)\n",
    "dataset_hat = torch.stack(X_hats)\n",
    "\n",
    "new_dm_reward = dm_reward(dataset @ W, dataset_hat, phi, temp=temperature)\n",
    "cum_dm_reward += new_dm_reward\n",
    "xW = gr_xW(new_dm_reward.item(), x_hat, phi, temp=temperature, attempts=5, iters=1_000)\n",
    "xWs.append(xW)\n",
    "pred_xWs = torch.stack(xWs)\n",
    "\n",
    "opt_new_dm_reward = dm_reward(dataset @ W, dataset, phi_opt, temp=temperature)\n",
    "opt_cum_dm_reward += opt_new_dm_reward\n",
    "\n",
    "rand_new_dm_reward = dm_reward(dataset @ W, dataset_hat, torch.rand((m, d + 1)), temp=temperature)\n",
    "rand_cum_dm_reward += rand_new_dm_reward\n",
    "\n",
    "lbls = [a[0] > a[1] for a in classify(x=dataset, phi=phi_opt, temp=temperature).T]\n",
    "preds = [a[0] > a[1] for a in classify(x=dataset_hat, phi=phi, temp=temperature).T]\n",
    "n = len(preds)\n",
    "print('Random:   ', rand_cum_dm_reward.item() / n, rand_new_dm_reward.item())\n",
    "print('Predicted:', cum_dm_reward.item() / n, new_dm_reward.item())\n",
    "print('Optimal:  ', opt_cum_dm_reward.item() / n, opt_new_dm_reward.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf5df701",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.gca().set_aspect('equal')\n",
    "plt.xlim(0, 1)\n",
    "plt.ylim(0, 1)\n",
    "plt.scatter(dataset_hat[:,0], dataset_hat[:,1], c=preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46075fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.gca().set_aspect('equal')\n",
    "plt.xlim(0, 1)\n",
    "plt.ylim(0, 1)\n",
    "plt.scatter(dataset[:,0], dataset[:,1], c=lbls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "28a573a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([tensor([0.5660, 0.5968]),\n",
       "  tensor([0.2822, 0.5415]),\n",
       "  tensor([0.8680, 0.5155]),\n",
       "  tensor([0.6200, 0.7289]),\n",
       "  tensor([0.5777, 0.7554]),\n",
       "  tensor([0.7386, 0.0548]),\n",
       "  tensor([0.7864, 0.9579]),\n",
       "  tensor([0.3811, 0.7748]),\n",
       "  tensor([0.7623, 0.2101]),\n",
       "  tensor([0.8287, 0.8251]),\n",
       "  tensor([0.8024, 0.4571]),\n",
       "  tensor([0.5852, 0.8803]),\n",
       "  tensor([-0.0120,  0.8002]),\n",
       "  tensor([0.2748, 0.7038]),\n",
       "  tensor([0.8191, 0.3681]),\n",
       "  tensor([0.8402, 0.4590]),\n",
       "  tensor([0.8449, 0.6641]),\n",
       "  tensor([0.0950, 0.8505]),\n",
       "  tensor([0.8668, 0.6186]),\n",
       "  tensor([0.5979, 0.8474]),\n",
       "  tensor([0.8834, 0.8363]),\n",
       "  tensor([0.8646, 0.3566]),\n",
       "  tensor([0.9986, 0.8688]),\n",
       "  tensor([0.7832, 0.4436]),\n",
       "  tensor([0.4421, 0.8744]),\n",
       "  tensor([0.9310, 0.8663])],\n",
       " tensor([[1.1406, 0.5860],\n",
       "         [0.8703, 0.4970],\n",
       "         [0.8457, 0.4636],\n",
       "         [0.4553, 0.3717],\n",
       "         [0.4538, 0.2851],\n",
       "         [0.9234, 0.4503],\n",
       "         [1.0727, 0.4733],\n",
       "         [0.4060, 0.9521],\n",
       "         [1.1650, 0.9142],\n",
       "         [0.4113, 0.1182],\n",
       "         [0.6450, 0.3688],\n",
       "         [0.2945, 0.2439],\n",
       "         [0.8296, 0.9796],\n",
       "         [0.9456, 1.2076],\n",
       "         [1.1874, 0.9849],\n",
       "         [1.1474, 0.8838],\n",
       "         [0.8241, 0.7164],\n",
       "         [0.7936, 1.0371],\n",
       "         [1.0337, 1.1502],\n",
       "         [0.2401, 0.6047],\n",
       "         [0.9705, 1.2204],\n",
       "         [1.1023, 1.1814],\n",
       "         [0.6588, 0.9620],\n",
       "         [1.1232, 1.1447],\n",
       "         [0.6461, 0.7530],\n",
       "         [0.5351, 0.6646]]))"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xWs, dataset @ W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a11b5eb3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
